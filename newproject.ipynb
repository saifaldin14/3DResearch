{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f268fb",
   "metadata": {},
   "source": [
    "### Environment Setup: ModelNet & PyTorch3D\n",
    "\n",
    "This section sets up the environment for 3D point cloud robustness experiments using PyTorch3D and ModelNet.\n",
    "\n",
    "**Requirements:**\n",
    "- PyTorch (with CUDA if available)\n",
    "- PyTorch3D\n",
    "- tqdm, matplotlib, numpy, pandas, scikit-learn\n",
    "\n",
    "**Note:** PyTorch3D requires a compatible PyTorch version. See [https://github.com/facebookresearch/pytorch3d/blob/main/INSTALL.md] for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549db793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch3D (uncomment if not already installed)\n",
    "# For CUDA 11.7 (adjust for your CUDA version):\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "# pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\n",
    "\n",
    "# If you are on CPU-only, use:\n",
    "# pip install torch torchvision torchaudio\n",
    "# pip install 'git+https://github.com/facebookresearch/pytorch3d.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47bcfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch3D is installed and ready.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "# PyTorch3D\n",
    "try:\n",
    "    import pytorch3d\n",
    "    from pytorch3d.loss import chamfer_distance\n",
    "    from pytorch3d.ops import sample_points_from_meshes\n",
    "    print(\"PyTorch3D is installed and ready.\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch3D is not installed. Please follow the instructions above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406482a",
   "metadata": {},
   "source": [
    "### Step 1: Download and Prepare ModelNet40 Data\n",
    "\n",
    "We will download the ModelNet40 dataset, extract it, and preprocess it into point clouds.\n",
    "\n",
    "- The dataset will be stored in a local directory (e.g., `./modelnet40`).\n",
    "- Each mesh will be sampled into a fixed number of points (e.g., 1024) for use in point cloud classification.\n",
    "- This step only needs to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e163dcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelNet40 already downloaded and extracted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "DATA_DIR = './modelnet40'\n",
    "MODELNET_URL = 'http://modelnet.cs.princeton.edu/ModelNet40.zip'\n",
    "ZIP_PATH = os.path.join(DATA_DIR, 'ModelNet40.zip')\n",
    "\n",
    "# Download ModelNet40 if not present\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "if not os.path.exists(os.path.join(DATA_DIR, 'ModelNet40')):\n",
    "    print('Downloading ModelNet40...')\n",
    "    urllib.request.urlretrieve(MODELNET_URL, ZIP_PATH)\n",
    "    print('Extracting ModelNet40...')\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('ModelNet40 already downloaded and extracted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3de64b",
   "metadata": {},
   "source": [
    "### Step 2: Create a PyTorch Dataset and DataLoader for ModelNet40 Point Clouds\n",
    "\n",
    "This step defines a PyTorch Dataset that loads ModelNet40 meshes, samples point clouds using PyTorch3D, and provides them for training and evaluation.\n",
    "\n",
    "- Each sample is a tuple: (point_cloud [N, 3], label)\n",
    "- The dataset supports on-the-fly mesh loading and point sampling.\n",
    "- You can cache sampled point clouds for faster subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f505b88",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "import trimesh\n",
    "import warnings\n",
    "\n",
    "class ModelNet40PointCloudDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', num_points=1024, cache=True, random_seed=42):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.num_points = num_points\n",
    "        self.cache = cache\n",
    "        self.random = np.random.RandomState(random_seed)\n",
    "        self.mesh_paths = []\n",
    "        self.labels = []\n",
    "        self.class_map = {}\n",
    "        self._build_file_list()\n",
    "        self._cache = {} if cache else None\n",
    "\n",
    "    def _build_file_list(self):\n",
    "        classes = sorted([d for d in os.listdir(os.path.join(self.root_dir, 'ModelNet40')) if os.path.isdir(os.path.join(self.root_dir, 'ModelNet40', d))])\n",
    "        self.class_map = {cls: i for i, cls in enumerate(classes)}\n",
    "        for cls in classes:\n",
    "            split_dir = os.path.join(self.root_dir, 'ModelNet40', cls, self.split)\n",
    "            if not os.path.exists(split_dir):\n",
    "                continue\n",
    "            for off_file in glob.glob(os.path.join(split_dir, '*.off')):\n",
    "                self.mesh_paths.append(off_file)\n",
    "                self.labels.append(self.class_map[cls])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mesh_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.cache and idx in self._cache:\n",
    "            return self._cache[idx]\n",
    "        mesh_path = self.mesh_paths[idx]\n",
    "        try:\n",
    "            # Load mesh using trimesh\n",
    "            mesh = trimesh.load(mesh_path)\n",
    "            verts = torch.tensor(mesh.vertices, dtype=torch.float32)\n",
    "            faces = torch.tensor(mesh.faces, dtype=torch.int64)\n",
    "            \n",
    "            if verts.shape[0] < self.num_points or faces.shape[0] == 0:\n",
    "                raise ValueError(\"Mesh has too few vertices or faces.\")\n",
    "            \n",
    "            mesh = Meshes(verts=[verts], faces=[faces])\n",
    "            points = sample_points_from_meshes(mesh, self.num_points)[0]  # [N, 3]\n",
    "            \n",
    "            if torch.isnan(points).any() or torch.isinf(points).any():\n",
    "                raise ValueError(\"Sampled points contain NaN or Inf.\")\n",
    "            label = self.labels[idx]\n",
    "            sample = (points, label)\n",
    "            if self.cache:\n",
    "                self._cache[idx] = sample\n",
    "            return sample\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Error loading item {idx}, path: {mesh_path}: {e}\")\n",
    "            # Return a dummy sample (random points, random label) to keep DataLoader running\n",
    "            points = torch.randn(self.num_points, 3)\n",
    "            label = 0\n",
    "            return (points, label)\n",
    "\n",
    "train_dataset = ModelNet40PointCloudDataset('./modelnet40/', split='train', num_points=1024)\n",
    "test_dataset = ModelNet40PointCloudDataset('./modelnet40/', split='test', num_points=1024)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "#test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "# Visualize a sample point cloud\n",
    "points, label = train_dataset[0]\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(points[:, 0].cpu(), points[:, 1].cpu(), points[:, 2].cpu(), s=2)\n",
    "ax.set_title(f'Class: {label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca22d137",
   "metadata": {},
   "source": [
    "### Step 3: Define a Custom Point Cloud Classification Model\n",
    "\n",
    "We define a simple custom model for point cloud classification. This model uses shared MLPs (1D convolutions), global max pooling, and fully connected layers.\n",
    "\n",
    "- Input: point cloud of shape (B, N, 3)\n",
    "- Output: logits for each class (B, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78513e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimplePointNet(nn.Module):\n",
    "    def __init__(self, num_classes=40, input_dim=3):\n",
    "        super().__init__()\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # x: (B, N, 3)\n",
    "        x = x.transpose(2, 1)  # (B, 3, N)\n",
    "        x = self.mlp1(x)      # (B, 256, N)\n",
    "        x = torch.max(x, 2)[0]  # (B, 256)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afbea9c",
   "metadata": {},
   "source": [
    "### Step 4: Adversarial Attacks and Corruptions for Point Clouds\n",
    "\n",
    "This section implements:\n",
    "- FGSM and PGD adversarial attacks for point clouds\n",
    "- Simple weather corruptions (Gaussian noise, snow, fog)\n",
    "\n",
    "All functions operate on torch tensors of shape (B, N, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66efb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# --- Adversarial Attacks ---\n",
    "def fgsm_attack(model, points, labels, epsilon):\n",
    "    \"\"\"\n",
    "    FGSM attack for point clouds.\n",
    "    Args:\n",
    "        model: classification model\n",
    "        points: (B, N, 3) input point cloud\n",
    "        labels: (B,) ground truth labels\n",
    "        epsilon: attack strength\n",
    "    Returns:\n",
    "        perturbed_points: (B, N, 3)\n",
    "    \"\"\"\n",
    "    points_adv = points.clone().detach().requires_grad_(True)\n",
    "    model.eval()  # Ensure model is in eval mode for attack\n",
    "    outputs = model(points_adv)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    # Zero out any existing gradients\n",
    "    if points_adv.grad is not None:\n",
    "        points_adv.grad.zero_()\n",
    "    loss.backward()\n",
    "    grad = points_adv.grad\n",
    "    perturbed_points = points + epsilon * grad.sign()\n",
    "    return perturbed_points.detach()\n",
    "\n",
    "def pgd_attack(model, points, labels, epsilon, alpha, num_iter):\n",
    "    \"\"\"\n",
    "    PGD attack for point clouds.\n",
    "    Args:\n",
    "        model: classification model\n",
    "        points: (B, N, 3)\n",
    "        labels: (B,)\n",
    "        epsilon: max perturbation\n",
    "        alpha: step size\n",
    "        num_iter: number of steps\n",
    "    Returns:\n",
    "        perturbed_points: (B, N, 3)\n",
    "    \"\"\"\n",
    "    ori_points = points.clone().detach()\n",
    "    perturbed = ori_points + torch.empty_like(ori_points).uniform_(-epsilon, epsilon)\n",
    "    perturbed.requires_grad = True\n",
    "    for _ in range(num_iter):\n",
    "        outputs = model(perturbed)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        grad = perturbed.grad.data\n",
    "        perturbed = perturbed + alpha * grad.sign()\n",
    "        perturbed = torch.max(torch.min(perturbed, ori_points + epsilon), ori_points - epsilon)\n",
    "        perturbed = perturbed.detach().requires_grad_(True)\n",
    "    return perturbed.detach()\n",
    "\n",
    "# --- Weather Corruptions ---\n",
    "def add_gaussian_noise(points, sigma=0.02):\n",
    "    \"\"\"Add Gaussian noise to point cloud (B, N, 3).\"\"\"\n",
    "    noise = torch.randn_like(points) * sigma\n",
    "    return points + noise\n",
    "\n",
    "def add_snow(points, density=0.1, snow_height=0.15):\n",
    "    \"\"\"Simulate snow by randomly dropping points above a certain z threshold.\"\"\"\n",
    "    B, N, _ = points.shape\n",
    "    mask = (points[..., 2] < (1.0 - snow_height)).float()\n",
    "    keep = (torch.rand(B, N, device=points.device) > density).float()\n",
    "    mask = mask * keep\n",
    "    # Set dropped points to zero (or random noise)\n",
    "    noisy_points = points * mask.unsqueeze(-1)\n",
    "    return noisy_points\n",
    "\n",
    "def add_fog(points, fog_strength=0.15):\n",
    "    \"\"\"Simulate fog by adding random noise and reducing contrast.\"\"\"\n",
    "    center = points.mean(dim=1, keepdim=True)\n",
    "    fog = (points - center) * (1 - fog_strength) + center\n",
    "    fog += torch.randn_like(points) * (fog_strength / 2)\n",
    "    return fog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import traceback\n",
    "\n",
    "# First, let's fix the dataset's __getitem__ method to handle errors better\n",
    "def safe_getitem(self, idx):\n",
    "    try:\n",
    "        if self.cache and idx in self._cache:\n",
    "            return self._cache[idx]\n",
    "        mesh_path = self.mesh_paths[idx]\n",
    "        mesh = trimesh.load(mesh_path)\n",
    "        verts, faces = torch.from_numpy(mesh.vertices).float(), torch.from_numpy(mesh.faces).long()\n",
    "        mesh = Meshes(verts=[verts], faces=[faces])\n",
    "        points = sample_points_from_meshes(mesh, self.num_points)[0]  # [N, 3]\n",
    "        label = self.labels[idx]\n",
    "        sample = (points, label)\n",
    "        if self.cache:\n",
    "            self._cache[idx] = sample\n",
    "        return sample\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading item {idx}, path: {self.mesh_paths[idx]}: {str(e)}\")\n",
    "        # Return a dummy sample of correct shape as fallback\n",
    "        dummy_points = torch.zeros((self.num_points, 3))\n",
    "        return dummy_points, 0\n",
    "\n",
    "# Apply the patched method to the dataset class\n",
    "ModelNet40PointCloudDataset.__getitem__ = safe_getitem\n",
    "\n",
    "# Create new data loaders with fewer workers\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "# Use a small subset for quick debugging/training\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "small_train_indices = list(range(0, 1024))  # Use only 256 samples for quick test\n",
    "small_test_indices = list(range(0, 256))   # Use only 64 samples for quick test\n",
    "\n",
    "small_train_dataset = Subset(train_dataset, small_train_indices)\n",
    "small_test_dataset = Subset(test_dataset, small_test_indices)\n",
    "\n",
    "small_train_loader = DataLoader(small_train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "small_test_loader = DataLoader(small_test_dataset, batch_size=16, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbd403",
   "metadata": {},
   "source": [
    "### Step 5: Advanced Real-World Corruptions for 3D Point Clouds\n",
    "\n",
    "Here we implement more realistic corruptions that simulate real-world challenges in 3D sensing:\n",
    "- **Occlusion**: Simulates objects blocking the view by removing spherical regions\n",
    "- **LiDAR Noise**: Distance-dependent noise and reflectivity issues\n",
    "- **Registration Errors**: Misalignment between multiple scans\n",
    "- **Rain Simulation**: Models streaks of rain in the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f05c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_occlusion(points, num_spheres=3, occlusion_radius=0.3):\n",
    "    \"\"\"\n",
    "    Simulates occlusion by completely removing points in spherical regions.\n",
    "    Args:\n",
    "        points: Point cloud tensor of shape (B, N, 3)\n",
    "        num_spheres: Number of occlusion spheres to create\n",
    "        occlusion_radius: Radius of occlusion sphere\n",
    "        debug: Print number of points removed\n",
    "    Returns:\n",
    "        Occluded point cloud with same shape as input, but with occluded points zeroed out\n",
    "    \"\"\"\n",
    "    B, N, _ = points.shape\n",
    "    device = points.device\n",
    "    occluded_points = points.clone()\n",
    "    for b in range(B):\n",
    "        keep_mask = torch.ones(N, dtype=torch.bool, device=device)\n",
    "        for _ in range(num_spheres):\n",
    "            center_idx = torch.randint(0, N, (1,), device=device)\n",
    "            center = points[b, center_idx, :].squeeze(0)\n",
    "            dist = torch.norm(points[b] - center, dim=1)\n",
    "            keep_mask &= (dist > occlusion_radius)\n",
    "        occluded_points[b][~keep_mask] = 0\n",
    "    return occluded_points\n",
    "\n",
    "def add_lidar_noise(points, distance_noise=0.01, reflectivity_drop=0.1):\n",
    "    \"\"\"Simulates LiDAR sensor noise - noise increases with distance from origin\n",
    "    and some points are completely missing due to reflectivity issues.\n",
    "    \n",
    "    Args:\n",
    "        points: Point cloud tensor of shape (B, N, 3)\n",
    "        distance_noise: Base noise level\n",
    "        reflectivity_drop: Probability of point dropout\n",
    "        \n",
    "    Returns:\n",
    "        Noisy point cloud with same shape as input\n",
    "    \"\"\"\n",
    "    B, N, _ = points.shape\n",
    "    device = points.device\n",
    "    \n",
    "    # Calculate distance from origin for each point\n",
    "    distances = torch.norm(points, dim=2)  # Shape: [B, N]\n",
    "    \n",
    "    # Noise scales with distance (farther = more noise)\n",
    "    scaled_noise = distance_noise * distances.unsqueeze(-1)  # Shape: [B, N, 1]\n",
    "    noise = torch.randn_like(points) * scaled_noise  # Shape: [B, N, 3]\n",
    "    \n",
    "    # Randomly drop points based on reflectivity simulation\n",
    "    keep_mask = (torch.rand(B, N, 1, device=device) > reflectivity_drop).float()\n",
    "    \n",
    "    # Apply noise and dropout\n",
    "    noisy_points = (points + noise) * keep_mask\n",
    "    \n",
    "    return noisy_points\n",
    "\n",
    "def add_registration_error(points, rotation_error=0.05, translation_error=0.05):\n",
    "    \"\"\"Simulates registration errors between multiple scans.\n",
    "    \n",
    "    Args:\n",
    "        points: Point cloud tensor of shape (B, N, 3)\n",
    "        rotation_error: Maximum rotation error in radians\n",
    "        translation_error: Maximum translation error\n",
    "        \n",
    "    Returns:\n",
    "        Point cloud with registration errors\n",
    "    \"\"\"\n",
    "    B, N, _ = points.shape\n",
    "    device = points.device\n",
    "    \n",
    "    # Deep copy the points\n",
    "    misaligned_points = points.clone()\n",
    "    \n",
    "    # Simulate different registration errors for each batch\n",
    "    for b in range(B):\n",
    "        # Randomly split points into two \"scans\"\n",
    "        split_idx = torch.randint(N//4, 3*N//4, (1,), device=device)\n",
    "        mask_first = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "        mask_first[:split_idx] = True\n",
    "        \n",
    "        # Generate random rotation error\n",
    "        angle = (torch.rand(1, device=device) * 2 - 1) * rotation_error\n",
    "        cos_val, sin_val = torch.cos(angle), torch.sin(angle)\n",
    "        \n",
    "        # Simple rotation matrix (around z-axis for simplicity)\n",
    "        R = torch.eye(3, device=device)\n",
    "        R[0, 0], R[0, 1] = cos_val, -sin_val\n",
    "        R[1, 0], R[1, 1] = sin_val, cos_val\n",
    "        \n",
    "        # Generate random translation error\n",
    "        T = (torch.rand(3, device=device) * 2 - 1) * translation_error\n",
    "        \n",
    "        # Apply transformation to second scan\n",
    "        misaligned_points[b, ~mask_first] = torch.matmul(\n",
    "            misaligned_points[b, ~mask_first], R.T) + T\n",
    "            \n",
    "    return misaligned_points\n",
    "\n",
    "def add_rain(points, rain_density=0.1, rain_length=0.1, direction=None):\n",
    "    \"\"\"Adds vertical rain streaks to the point cloud.\n",
    "    \n",
    "    Args:\n",
    "        points: Point cloud tensor of shape (B, N, 3)\n",
    "        rain_density: Density of rain (0-1)\n",
    "        rain_length: Length of rain streaks\n",
    "        direction: Optional rain direction vector, otherwise vertical\n",
    "        \n",
    "    Returns:\n",
    "        Point cloud with added rain\n",
    "    \"\"\"\n",
    "    B, N, _ = points.shape\n",
    "    device = points.device\n",
    "    \n",
    "    # Set rain direction (default is vertical down)\n",
    "    if direction is None:\n",
    "        direction = torch.tensor([0.0, 0.0, -1.0], device=device)\n",
    "    else:\n",
    "        direction = F.normalize(direction, dim=0)\n",
    "    \n",
    "    # Number of raindrops to add\n",
    "    num_drops = int(N * rain_density)\n",
    "    \n",
    "    # Result tensor with original points\n",
    "    result = points.clone()\n",
    "    \n",
    "    for b in range(B):\n",
    "        if num_drops > 0:\n",
    "            # Randomly select positions for raindrops above the scene\n",
    "            # Find the highest z-value in the scene and place rain above it\n",
    "            max_z = points[b, :, 2].max().item()\n",
    "            \n",
    "            # Create rain start positions\n",
    "            x_range = points[b, :, 0].max() - points[b, :, 0].min()\n",
    "            y_range = points[b, :, 1].max() - points[b, :, 1].min()\n",
    "            x_min, y_min = points[b, :, 0].min(), points[b, :, 1].min()\n",
    "            \n",
    "            # Create random starting positions for raindrops\n",
    "            rain_x = torch.rand(num_drops, device=device) * x_range + x_min\n",
    "            rain_y = torch.rand(num_drops, device=device) * y_range + y_min\n",
    "            rain_z = torch.ones(num_drops, device=device) * (max_z + 0.1)\n",
    "            \n",
    "            rain_starts = torch.stack([rain_x, rain_y, rain_z], dim=1)\n",
    "            \n",
    "            # Create rain streaks (start and end points)\n",
    "            rain_ends = rain_starts + direction * rain_length\n",
    "            \n",
    "            # Sample points along the rain streaks\n",
    "            t = torch.rand(num_drops, 5, device=device).unsqueeze(-1)  # 5 points per streak\n",
    "            rain_points = rain_starts.unsqueeze(1) * (1 - t) + rain_ends.unsqueeze(1) * t\n",
    "            rain_points = rain_points.view(-1, 3)\n",
    "            \n",
    "            # Add the rain points by replacing some of the original points\n",
    "            replace_indices = torch.randperm(N, device=device)[:rain_points.shape[0]]\n",
    "            result[b, replace_indices] = rain_points[:replace_indices.shape[0]]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples of the corruptions\n",
    "def visualize_corruption(points, corrupted_points, title):\n",
    "    \"\"\"Visualize original vs corrupted point cloud with enhanced visibility\"\"\"\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Original\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.scatter(points[0, :, 0].cpu(), \n",
    "               points[0, :, 1].cpu(), \n",
    "               points[0, :, 2].cpu(), s=5, alpha=0.7)  # Larger points\n",
    "    ax1.set_title('Original', fontsize=14)\n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_zlabel('Z')\n",
    "    \n",
    "    # Corrupted\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    # Filter out zero points for better visualization\n",
    "    nonzero_mask = ~torch.all(corrupted_points[0] == 0, dim=1)\n",
    "    if nonzero_mask.sum() > 0:  # Check if any points remain\n",
    "        ax2.scatter(corrupted_points[0, nonzero_mask, 0].cpu(), \n",
    "                   corrupted_points[0, nonzero_mask, 1].cpu(), \n",
    "                   corrupted_points[0, nonzero_mask, 2].cpu(), s=5, alpha=0.7)\n",
    "    ax2.set_title(title, fontsize=14)\n",
    "    ax2.set_xlabel('X')\n",
    "    ax2.set_ylabel('Y')\n",
    "    ax2.set_zlabel('Z')\n",
    "    \n",
    "    # Set same view for both subplots\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_xlim([points[0, :, 0].min().item(), points[0, :, 0].max().item()])\n",
    "        ax.set_ylim([points[0, :, 1].min().item(), points[0, :, 1].max().item()])\n",
    "        ax.set_zlim([points[0, :, 2].min().item(), points[0, :, 2].max().item()])\n",
    "        ax.view_init(elev=30, azim=45)  # Set the same viewing angle\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eba19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of point clouds for visualization\n",
    "points, _ = next(iter(small_test_loader))\n",
    "\n",
    "# Visualize occlusion with more dramatic settings\n",
    "occluded_points = add_occlusion(points, num_spheres=10, occlusion_radius=200)\n",
    "visualize_corruption(points, occluded_points, 'Occlusion')\n",
    "\n",
    "# Visualize LiDAR noise\n",
    "lidar_points = add_lidar_noise(points, distance_noise=0.03, reflectivity_drop=0.2)\n",
    "visualize_corruption(points, lidar_points, 'LiDAR Noise')\n",
    "\n",
    "# Visualize registration errors\n",
    "misaligned_points = add_registration_error(points, rotation_error=0.5, translation_error=0.4)\n",
    "visualize_corruption(points, misaligned_points, 'Registration Error')\n",
    "\n",
    "# Visualize rain\n",
    "rainy_points = add_rain(points, rain_density=0.05, rain_length=0.2)\n",
    "visualize_corruption(points, rainy_points, 'Rain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b355c",
   "metadata": {},
   "source": [
    "### Step 6: Training and Evaluation Pipeline\n",
    "\n",
    "This section provides a simple training and evaluation loop for the custom model, supporting clean, adversarial, and corrupted data.\n",
    "\n",
    "You can toggle between clean, adversarial, and corrupted training/evaluation by changing the `mode` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d70c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for point clouds\n",
    "\n",
    "def random_rotate_point_cloud(points):\n",
    "    \"\"\"Randomly rotate the point cloud along the up-axis (z).\"\"\"\n",
    "    B, N, C = points.shape\n",
    "    angles = torch.rand(B) * 2 * np.pi\n",
    "    cos_vals = torch.cos(angles)\n",
    "    sin_vals = torch.sin(angles)\n",
    "    rotation_matrices = torch.zeros((B, 3, 3), device=points.device)\n",
    "    rotation_matrices[:, 0, 0] = cos_vals\n",
    "    rotation_matrices[:, 0, 1] = -sin_vals\n",
    "    rotation_matrices[:, 1, 0] = sin_vals\n",
    "    rotation_matrices[:, 1, 1] = cos_vals\n",
    "    rotation_matrices[:, 2, 2] = 1\n",
    "    rotated = torch.bmm(points, rotation_matrices)\n",
    "    return rotated\n",
    "\n",
    "def random_jitter_point_cloud(points, sigma=0.01, clip=0.05):\n",
    "    \"\"\"Randomly jitter points. jittering is per point.\"\"\"\n",
    "    jitter = torch.clamp(sigma * torch.randn_like(points), -clip, clip)\n",
    "    return points + jitter\n",
    "\n",
    "# Update train_one_epoch to use augmentation\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, mode='clean', attack_params=None, corruption_fn=None, augment=True):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    for points, labels in loader:\n",
    "        points, labels = points.to(device), labels.to(device)\n",
    "        if augment:\n",
    "            points = random_rotate_point_cloud(points)\n",
    "            points = random_jitter_point_cloud(points)\n",
    "        optimizer.zero_grad()\n",
    "        # For adversarial training, compute attack in eval mode, then train on adv examples\n",
    "        if mode == 'fgsm':\n",
    "            model.eval()\n",
    "            points = fgsm_attack(model, points, labels, **attack_params)\n",
    "            model.train()\n",
    "        elif mode == 'pgd':\n",
    "            model.eval()\n",
    "            points = pgd_attack(model, points, labels, **attack_params)\n",
    "            model.train()\n",
    "        elif mode == 'corrupt' and corruption_fn is not None:\n",
    "            points = corruption_fn(points)\n",
    "        outputs = model(points)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * points.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total += points.size(0)\n",
    "    avg_loss = total_loss / total\n",
    "    avg_acc = total_correct / total\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def evaluate(model, loader, device, mode='clean', attack_params=None, corruption_fn=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    for points, labels in loader:\n",
    "        points, labels = points.to(device), labels.to(device)\n",
    "        if mode == 'fgsm':\n",
    "            # Enable grad for attack, then disable for forward\n",
    "            points_adv = points.clone().detach().requires_grad_(True)\n",
    "            outputs = model(points_adv)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            # Compute grad outside of no_grad context\n",
    "            grad = torch.autograd.grad(loss, points_adv)[0]\n",
    "            adv_points = points + attack_params['epsilon'] * grad.sign()\n",
    "            adv_points = adv_points.detach()\n",
    "            outputs = model(adv_points)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            points = adv_points\n",
    "        elif mode == 'pgd':\n",
    "            adv_points = pgd_attack(model, points, labels, **attack_params)\n",
    "            outputs = model(adv_points)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            points = adv_points\n",
    "        elif mode == 'corrupt' and corruption_fn is not None:\n",
    "            points = corruption_fn(points)\n",
    "            outputs = model(points)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            outputs = model(points)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "        total_loss += loss.item() * points.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total += points.size(0)\n",
    "    avg_loss = total_loss / total\n",
    "    avg_acc = total_correct / total\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimplePointNet(num_classes=40).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d014da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean training\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, small_train_loader, optimizer, device, mode='clean', augment=True)\n",
    "    val_loss, val_acc = evaluate(model, small_test_loader, device, mode='clean')\n",
    "    print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13069f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training (FGSM example)\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, small_train_loader, optimizer, device, mode='fgsm', attack_params={'epsilon':0.02})\n",
    "    val_loss, val_acc = evaluate(model, small_test_loader, device, mode='fgsm', attack_params={'epsilon':0.02})\n",
    "    print(f\"[FGSM] Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2832a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training (PGD example)\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, small_train_loader, optimizer, device, mode='pgd', attack_params={'epsilon':0.02})\n",
    "    val_loss, val_acc = evaluate(model, small_test_loader, device, mode='pgd', attack_params={'epsilon':0.02})\n",
    "    print(f\"[PGD] Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training (corruption example)\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, small_train_loader, optimizer, device, mode='corrupt', attack_params={'epsilon':0.02, 'alpha':0.01, 'num_iter':10})\n",
    "    val_loss, val_acc = evaluate(model, small_test_loader, device, mode='corrupt', attack_params={'epsilon':0.02, 'alpha':0.01, 'num_iter':10})\n",
    "    print(f\"[CORRUPT] Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
