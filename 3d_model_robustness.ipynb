{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import random\n",
    "import copy\n",
    "from scipy.spatial.transform import Rotation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from scipy import stats\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetAbstractionLayer(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp):\n",
    "        super(SetAbstractionLayer, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        \n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        \n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: input points position data, [B, N, 3]\n",
    "            points: input points data, [B, N, D]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, S, 3]\n",
    "            new_points_concat: sample points feature data, [B, S, D']\n",
    "        \"\"\"\n",
    "        # Simplified implementation - in a real model this would use farthest point sampling\n",
    "        # and ball query operations from PointNet++ \n",
    "        B, N, C = xyz.shape\n",
    "        if self.npoint is None:\n",
    "            S = N\n",
    "        else:\n",
    "            S = min(self.npoint, N)\n",
    "            \n",
    "        # Simplified: just use the first S points instead of FPS\n",
    "        new_xyz = xyz[:, :S, :]\n",
    "        \n",
    "        # Simplified feature aggregation (in real implementation would be grouped by radius)\n",
    "        if points is not None:\n",
    "            new_points = points[:, :S, :]\n",
    "        else:\n",
    "            new_points = new_xyz\n",
    "            \n",
    "        # Apply MLP - simplified for this example\n",
    "        new_points = new_points.permute(0, 2, 1).unsqueeze(-1)\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = torch.relu(bn(conv(new_points)))\n",
    "        \n",
    "        new_points = new_points.squeeze(-1).permute(0, 2, 1)\n",
    "        return new_xyz, new_points\n",
    "\n",
    "class PointNet2Classification(nn.Module):\n",
    "    def __init__(self, num_classes=40, normal_channel=False):\n",
    "        super(PointNet2Classification, self).__init__()\n",
    "        in_channel = 6 if normal_channel else 3\n",
    "        \n",
    "        self.normal_channel = normal_channel\n",
    "        \n",
    "        # SA modules\n",
    "        self.sa1 = SetAbstractionLayer(npoint=512, radius=0.2, nsample=32, \n",
    "                                        in_channel=in_channel, mlp=[64, 64, 128])\n",
    "        self.sa2 = SetAbstractionLayer(npoint=128, radius=0.4, nsample=64, \n",
    "                                        in_channel=128 + 3, mlp=[128, 128, 256])\n",
    "        self.sa3 = SetAbstractionLayer(npoint=None, radius=None, nsample=None, \n",
    "                                        in_channel=256 + 3, mlp=[256, 512, 1024])\n",
    "        \n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.drop1 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.drop2 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        B, _, _ = xyz.shape\n",
    "        if self.normal_channel:\n",
    "            norm = xyz[:, 3:, :]\n",
    "            xyz = xyz[:, :3, :]\n",
    "        else:\n",
    "            norm = None\n",
    "        \n",
    "        # Transpose to match expected input format\n",
    "        xyz = xyz.transpose(2, 1)\n",
    "        \n",
    "        # Set Abstraction layers\n",
    "        l1_xyz, l1_points = self.sa1(xyz, norm)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "        \n",
    "        # FC layers\n",
    "        x = l3_points.view(B, 1024)\n",
    "        x = self.drop1(torch.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.drop2(torch.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def _init_pointnet_plus_plus(num_classes=40):\n",
    "    \"\"\"Create and initialize a PointNet++ classification model\"\"\"\n",
    "    model = PointNet2Classification(num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConv(nn.Module):\n",
    "    def __init__(self, k, in_channels, out_channels):\n",
    "        super(EdgeConv, self).__init__()\n",
    "        self.k = k\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        \n",
    "    def knn(self, x, k):\n",
    "        inner = -2 * torch.matmul(x.transpose(2, 1), x)\n",
    "        xx = torch.sum(x**2, dim=1, keepdim=True)\n",
    "        distance = -xx - inner - xx.transpose(2, 1)\n",
    "        \n",
    "        idx = distance.topk(k=k, dim=-1)[1]\n",
    "        return idx\n",
    "    \n",
    "    def get_graph_feature(self, x, k=20):\n",
    "        batch_size, num_dims, num_points = x.size()\n",
    "        idx = self.knn(x, k)\n",
    "        idx_base = torch.arange(0, batch_size, device=x.device).view(-1, 1, 1) * num_points\n",
    "        idx = idx + idx_base\n",
    "        idx = idx.view(-1)\n",
    "        \n",
    "        x = x.transpose(2, 1).contiguous()\n",
    "        feature = x.view(batch_size * num_points, -1)[idx, :]\n",
    "        feature = feature.view(batch_size, num_points, k, num_dims)\n",
    "        x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
    "        \n",
    "        feature = torch.cat((feature - x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
    "        return feature\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.get_graph_feature(x, self.k)\n",
    "        x = self.conv(x)\n",
    "        x = x.max(dim=-1, keepdim=False)[0]\n",
    "        return x\n",
    "\n",
    "class DGCNN(nn.Module):\n",
    "    def __init__(self, num_classes=40, k=20):\n",
    "        super(DGCNN, self).__init__()\n",
    "        self.k = k\n",
    "        \n",
    "        # Edge convolution layers\n",
    "        self.edge_conv1 = EdgeConv(k=k, in_channels=3, out_channels=64)\n",
    "        self.edge_conv2 = EdgeConv(k=k, in_channels=64, out_channels=64)\n",
    "        self.edge_conv3 = EdgeConv(k=k, in_channels=64, out_channels=128)\n",
    "        self.edge_conv4 = EdgeConv(k=k, in_channels=128, out_channels=256)\n",
    "        \n",
    "        # MLP layers\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv1d(512, 1024, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input transform\n",
    "        batch_size = x.size(0)\n",
    "        if x.shape[1] == 3 and len(x.shape) == 3:  # BxCxN format\n",
    "            pass\n",
    "        else:  # Assuming BxNxC format (like PointNet)\n",
    "            x = x.transpose(2, 1)\n",
    "            \n",
    "        # Extract edge features\n",
    "        x1 = self.edge_conv1(x)\n",
    "        x2 = self.edge_conv2(x1)\n",
    "        x3 = self.edge_conv3(x2)\n",
    "        x4 = self.edge_conv4(x3)\n",
    "        \n",
    "        # Concatenate features\n",
    "        x = torch.cat([x1, x2, x3, x4], dim=1)\n",
    "        \n",
    "        # MLP\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        # Global max pooling\n",
    "        x = torch.max(x, 2)[0]\n",
    "        \n",
    "        # FC layers\n",
    "        x = self.drop1(torch.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.drop2(torch.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def _init_dgcnn(num_classes=40):\n",
    "    \"\"\"Create and initialize a DGCNN classification model\"\"\"\n",
    "    model = DGCNN(num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointMLP(nn.Module):\n",
    "    def __init__(self, num_classes=40, points=1024, embed_dim=64):\n",
    "        super(PointMLP, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.points = points\n",
    "        \n",
    "        # Point embedding layers\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(3, embed_dim, 1),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(embed_dim, embed_dim, 1),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Hierarchical feature extraction layers\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(embed_dim, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Handle input format (B, N, 3) or (B, 3, N)\n",
    "        batch_size = x.size(0)\n",
    "        if x.shape[1] != 3 and x.shape[2] == 3:\n",
    "            x = x.transpose(2, 1)\n",
    "        \n",
    "        # Feature extraction\n",
    "        x = self.embedding(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = torch.max(x, 2)[0]\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def _init_pointmlp(num_classes=40):\n",
    "    \"\"\"Create and initialize a PointMLP classification model\"\"\"\n",
    "    model = PointMLP(num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointAttentionNet(nn.Module):\n",
    "    def __init__(self, num_classes=40, num_points=1024, embed_dim=128):\n",
    "        super(PointAttentionNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Point embedding\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(3, embed_dim, 1),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Self-attention modules\n",
    "        self.self_attn1 = PointSelfAttention(embed_dim, 4)\n",
    "        self.self_attn2 = PointSelfAttention(embed_dim, 4)\n",
    "        \n",
    "        # Feature processing after attention\n",
    "        self.feature_conv = nn.Sequential(\n",
    "            nn.Conv1d(embed_dim, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Handle input format (B, N, 3) or (B, 3, N)\n",
    "        batch_size = x.size(0)\n",
    "        if x.shape[1] != 3 and x.shape[2] == 3:\n",
    "            x = x.transpose(2, 1)\n",
    "        \n",
    "        # Feature embedding\n",
    "        x = self.embedding(x)  # B x embed_dim x N\n",
    "        \n",
    "        # Apply attention\n",
    "        x = self.self_attn1(x)\n",
    "        x = self.self_attn2(x)\n",
    "        \n",
    "        # Feature processing\n",
    "        x = self.feature_conv(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = torch.max(x, 2)[0]\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class PointSelfAttention(nn.Module):\n",
    "    def __init__(self, channels, heads=4):\n",
    "        super(PointSelfAttention, self).__init__()\n",
    "        self.heads = heads\n",
    "        self.channels = channels\n",
    "        self.head_dim = channels // heads\n",
    "        assert self.head_dim * heads == channels, \"channels must be divisible by heads\"\n",
    "        \n",
    "        self.qkv_conv = nn.Conv1d(channels, channels * 3, 1, bias=False)\n",
    "        self.out_conv = nn.Conv1d(channels, channels, 1)\n",
    "        \n",
    "        self.norm1 = nn.BatchNorm1d(channels)\n",
    "        self.norm2 = nn.BatchNorm1d(channels)\n",
    "        \n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Conv1d(channels, channels * 2, 1),\n",
    "            nn.BatchNorm1d(channels * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(channels * 2, channels, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: B x C x N\n",
    "        batch_size, C, N = x.shape\n",
    "        residual = x\n",
    "        \n",
    "        # Self-attention\n",
    "        qkv = self.qkv_conv(x)  # B x 3C x N\n",
    "        qkv = qkv.reshape(batch_size, 3, self.heads, self.head_dim, N)\n",
    "        q, k, v = qkv[:, 0], qkv[:, 1], qkv[:, 2]  # B x H x D x N\n",
    "        \n",
    "        # Compute attention scores\n",
    "        q = q.permute(0, 1, 3, 2)  # B x H x N x D\n",
    "        k = k.permute(0, 1, 2, 3)  # B x H x D x N\n",
    "        attn = torch.matmul(q, k) / (self.head_dim ** 0.5)  # B x H x N x N\n",
    "        attn = torch.softmax(attn, dim=-1)\n",
    "        \n",
    "        # Apply attention\n",
    "        v = v.permute(0, 1, 3, 2)  # B x H x N x D\n",
    "        x = torch.matmul(attn, v)  # B x H x N x D\n",
    "        x = x.permute(0, 1, 3, 2).reshape(batch_size, C, N)\n",
    "        \n",
    "        # Output projection\n",
    "        x = self.out_conv(x)\n",
    "        x = self.norm1(x + residual)\n",
    "        \n",
    "        # Feed forward\n",
    "        residual = x\n",
    "        x = self.ff(x)\n",
    "        x = self.norm2(x + residual)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def _init_custom_attention(num_classes=40):\n",
    "    \"\"\"Create and initialize a custom attention-based model\"\"\"\n",
    "    return PointAttentionNet(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model architectures\n",
    "# Note: These would typically be imported from external files\n",
    "# For demonstration, we'll include placeholders for imports\n",
    "\n",
    "# from models.pointnet2 import PointNet2Classification\n",
    "# from models.dgcnn import DGCNN\n",
    "# from models.pointmlp import PointMLP\n",
    "# from models.custom_attention import PointAttentionNet\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model_name, pretrained_path, num_classes=40):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Initialize selected model\n",
    "        if model_name == \"pointnet++\":\n",
    "            self.model = self._init_pointnet_plus_plus()\n",
    "        elif model_name == \"dgcnn\":\n",
    "            self.model = self._init_dgcnn()\n",
    "        elif model_name == \"pointmlp\":\n",
    "            self.model = self._init_pointmlp()\n",
    "        elif model_name == \"custom\":\n",
    "            self.model = self._init_custom_attention()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "            \n",
    "        # Load pre-trained weights\n",
    "        self.load_pretrained(pretrained_path)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "    def _init_pointnet_plus_plus(self):\n",
    "        return PointNet2Classification(num_classes=self.num_classes)\n",
    "        \n",
    "    def _init_dgcnn(self):\n",
    "        # Placeholder for DGCNN initialization\n",
    "        return DGCNN(num_classes=self.num_classes)\n",
    "        \n",
    "    def _init_pointmlp(self):\n",
    "        # Placeholder for PointMLP initialization\n",
    "        return PointMLP(num_classes=self.num_classes)\n",
    "        \n",
    "    def _init_custom_attention(self):\n",
    "        # Placeholder for custom attention model initialization\n",
    "        # return PointAttentionNet(num_classes=self.num_classes)\n",
    "        print(\"Initializing custom attention model\")\n",
    "        return None  # Replace with actual model\n",
    "    \n",
    "    def load_pretrained(self, path):\n",
    "        # Load pre-trained weights if the model exists\n",
    "        if self.model is not None and os.path.exists(path):\n",
    "            print(f\"Loading pre-trained weights for {self.model_name} from {path}\")\n",
    "            # self.model.load_state_dict(torch.load(path))\n",
    "        else:\n",
    "            print(f\"No pre-trained weights found at {path}\")\n",
    "    \n",
    "    def evaluate_adversarial_robustness(self, test_loader, attack_type, epsilon):\n",
    "        \"\"\"\n",
    "        Evaluate model robustness against adversarial attacks\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_loader: DataLoader containing test data\n",
    "        attack_type: str, type of attack (e.g., 'fgsm', 'pgd')\n",
    "        epsilon: float, attack strength\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        accuracy: float, model accuracy under adversarial attack\n",
    "        \"\"\"\n",
    "        # Placeholder for adversarial evaluation\n",
    "        print(f\"Evaluating {self.model_name} against {attack_type} with ε={epsilon}\")\n",
    "        return 0.0\n",
    "    \n",
    "    def evaluate_corruption_robustness(self, test_loader, corruption_type, severity):\n",
    "        \"\"\"\n",
    "        Evaluate model robustness against environmental corruptions\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_loader: DataLoader containing test data\n",
    "        corruption_type: str, type of corruption (e.g., 'gaussian', 'impulse')\n",
    "        severity: int, corruption severity level (usually 1-5)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        accuracy: float, model accuracy under corruption\n",
    "        \"\"\"\n",
    "        # Placeholder for corruption evaluation\n",
    "        print(f\"Evaluating {self.model_name} against {corruption_type} corruption at severity {severity}\")\n",
    "        return 0.0\n",
    "\n",
    "# Example usage:\n",
    "# evaluator = ModelEvaluator(\"pointnet++\", \"pretrained/pointnet_modelnet40.pth\")\n",
    "# adv_acc = evaluator.evaluate_adversarial_robustness(test_loader, \"pgd\", 0.1)\n",
    "# corr_acc = evaluator.evaluate_corruption_robustness(test_loader, \"gaussian_noise\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import random\n",
    "from scipy.spatial.transform import Rotation\n",
    "import math\n",
    "\n",
    "class ModelNet40Dataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', num_points=1024, transform=None, random_rotation=True, class_balance=True):\n",
    "        \"\"\"\n",
    "        ModelNet40 Dataset for 3D point cloud classification\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        root_dir: str, path to the ModelNet40 dataset\n",
    "        split: str, 'train' or 'test'\n",
    "        num_points: int, number of points to sample (1024, 2048, or 4096)\n",
    "        transform: callable, optional transform to be applied on a sample\n",
    "        random_rotation: bool, whether to apply random rotation augmentation\n",
    "        class_balance: bool, whether to use class balancing\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.num_points = num_points\n",
    "        self.transform = transform\n",
    "        self.random_rotation = random_rotation\n",
    "        \n",
    "        # Get all class folders\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # Get all model files\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for cls_name in self.classes:\n",
    "            cls_path = os.path.join(root_dir, cls_name, split)\n",
    "            if os.path.exists(cls_path):\n",
    "                model_files = glob.glob(os.path.join(cls_path, '*.off'))\n",
    "                self.files.extend(model_files)\n",
    "                self.labels.extend([self.class_to_idx[cls_name]] * len(model_files))\n",
    "        \n",
    "        # Prepare weights for class balancing\n",
    "        self.weights = None\n",
    "        if class_balance:\n",
    "            # Count instances per class\n",
    "            class_counts = np.zeros(len(self.classes))\n",
    "            for label in self.labels:\n",
    "                class_counts[label] += 1\n",
    "            # Calculate weights inversely proportional to class frequency\n",
    "            self.weights = 1.0 / class_counts\n",
    "            # Assign weight to each sample\n",
    "            self.sample_weights = np.array([self.weights[label] for label in self.labels])\n",
    "            self.sample_weights = torch.from_numpy(self.sample_weights).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load point cloud (placeholder - actual loading depends on file format)\n",
    "        # For OFF files, you'd parse the OFF format\n",
    "        # For this example, we'll generate a random point cloud\n",
    "        # In practice, replace this with actual file loading\n",
    "        points = np.random.rand(1024, 3)  # Placeholder\n",
    "        \n",
    "        # Sample num_points points\n",
    "        if points.shape[0] > self.num_points:\n",
    "            indices = np.random.choice(points.shape[0], self.num_points, replace=False)\n",
    "            points = points[indices]\n",
    "        elif points.shape[0] < self.num_points:\n",
    "            # Upsample by duplicating\n",
    "            indices = np.random.choice(points.shape[0], self.num_points - points.shape[0], replace=True)\n",
    "            points = np.vstack([points, points[indices]])\n",
    "        \n",
    "        # Normalize to unit sphere\n",
    "        center = np.mean(points, axis=0)\n",
    "        points = points - center\n",
    "        dist = np.max(np.sqrt(np.sum(points ** 2, axis=1)))\n",
    "        points = points / dist\n",
    "        \n",
    "        # Apply random rotation\n",
    "        if self.split == 'train' and self.random_rotation:\n",
    "            # Random rotation around z-axis\n",
    "            theta = np.random.uniform(0, 2 * np.pi)\n",
    "            rotation_matrix = np.array([\n",
    "                [np.cos(theta), -np.sin(theta), 0],\n",
    "                [np.sin(theta), np.cos(theta), 0],\n",
    "                [0, 0, 1]\n",
    "            ])\n",
    "            points = points @ rotation_matrix\n",
    "        \n",
    "        if self.transform:\n",
    "            points = self.transform(points)\n",
    "        \n",
    "        return points, label\n",
    "\n",
    "class PointCloudCorruptor:\n",
    "    \"\"\"Class for adding various environmental corruptions to point clouds\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_snow(points, density=0.1, scatter_strength=0.05):\n",
    "        \"\"\"Add snow effect to point cloud\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: np.ndarray, shape (N, 3)\n",
    "        density: float, snow density (0.0-1.0)\n",
    "        scatter_strength: float, scattering effect strength\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        corrupted_points: np.ndarray, shape (N, 3)\n",
    "        \"\"\"\n",
    "        num_points = points.shape[0]\n",
    "        num_snow_points = int(num_points * density)\n",
    "        \n",
    "        # Generate snow points\n",
    "        snow_points = np.random.uniform(-1, 1, size=(num_snow_points, 3))\n",
    "        \n",
    "        # Create scattering effect\n",
    "        scatter = np.random.normal(0, scatter_strength, size=(num_points, 3))\n",
    "        points_scattered = points + scatter\n",
    "        \n",
    "        # Randomly select points to replace with snow\n",
    "        indices = np.random.choice(num_points, num_snow_points, replace=False)\n",
    "        points_scattered[indices] = snow_points\n",
    "        \n",
    "        return points_scattered\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_rain(points, density=0.1, drop_length=0.05):\n",
    "        \"\"\"Add rain effect to point cloud\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: np.ndarray, shape (N, 3)\n",
    "        density: float, rain density (0.0-1.0)\n",
    "        drop_length: float, length of rain drops\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        corrupted_points: np.ndarray, shape (N, 3)\n",
    "        \"\"\"\n",
    "        num_points = points.shape[0]\n",
    "        num_rain_points = int(num_points * density)\n",
    "        \n",
    "        # Generate rain points (starting positions)\n",
    "        rain_points = np.random.uniform(-1, 1, size=(num_rain_points, 3))\n",
    "        # Make rain streaks by extending in mostly downward direction\n",
    "        rain_directions = np.random.normal(0, 0.1, size=(num_rain_points, 2))\n",
    "        rain_directions = np.column_stack([rain_directions, -np.abs(np.random.normal(0, 0.5, num_rain_points))])\n",
    "        rain_directions /= np.linalg.norm(rain_directions, axis=1, keepdims=True)\n",
    "        \n",
    "        # Create rain droplet streaks\n",
    "        rain_streaks = rain_points + rain_directions * drop_length\n",
    "        \n",
    "        # Randomly select points to replace with rain\n",
    "        indices = np.random.choice(num_points, num_rain_points, replace=False)\n",
    "        points_with_rain = points.copy()\n",
    "        points_with_rain[indices] = rain_streaks\n",
    "        \n",
    "        return points_with_rain\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_fog(points, density=0.2):\n",
    "        \"\"\"Add fog effect to point cloud\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: np.ndarray, shape (N, 3)\n",
    "        density: float, fog density (0.0-1.0)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        corrupted_points: np.ndarray, shape (N, 3)\n",
    "        \"\"\"\n",
    "        num_points = points.shape[0]\n",
    "        \n",
    "        # Calculate distance from origin for each point\n",
    "        distances = np.linalg.norm(points, axis=1)\n",
    "        \n",
    "        # Attenuate points based on distance and fog density\n",
    "        attenuation = np.exp(-density * distances)\n",
    "        \n",
    "        # Apply attenuation: closer to 0 means more fog effect\n",
    "        # We'll add random displacement proportional to fog intensity\n",
    "        fog_displacement = (1 - attenuation).reshape(-1, 1) * np.random.normal(0, 0.1, size=(num_points, 3))\n",
    "        points_with_fog = points + fog_displacement\n",
    "        \n",
    "        # Randomly drop some distant points (completely obscured by fog)\n",
    "        dropout_prob = 1 - np.exp(-density * distances * 2)\n",
    "        dropout_mask = np.random.random(num_points) > dropout_prob\n",
    "        \n",
    "        # Create a mix of original and fogged points\n",
    "        return points_with_fog * dropout_mask.reshape(-1, 1) + (1 - dropout_mask.reshape(-1, 1)) * np.random.uniform(-0.1, 0.1, size=(num_points, 3))\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_gaussian_noise(points, sigma=0.02):\n",
    "        \"\"\"Add Gaussian noise to point cloud\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: np.ndarray, shape (N, 3)\n",
    "        sigma: float, standard deviation relative to object size\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        corrupted_points: np.ndarray, shape (N, 3)\n",
    "        \"\"\"\n",
    "        noise = np.random.normal(0, sigma, size=points.shape)\n",
    "        return points + noise\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_depth_noise(points, k=0.05):\n",
    "        \"\"\"Add depth-dependent noise (more noise at greater distances)\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: np.ndarray, shape (N, 3)\n",
    "        k: float, noise coefficient\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        corrupted_points: np.ndarray, shape (N, 3)\n",
    "        \"\"\"\n",
    "        # Calculate distance from origin\n",
    "        distances = np.linalg.norm(points, axis=1)\n",
    "        \n",
    "        # Scale noise by distance (farther = more noise)\n",
    "        noise_scale = k * distances.reshape(-1, 1)\n",
    "        noise = np.random.normal(0, 1, size=points.shape) * noise_scale\n",
    "        \n",
    "        return points + noise\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_occlusion(points, ratio=0.2, mode='random'):\n",
    "        \"\"\"Add occlusion to point cloud\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: np.ndarray, shape (N, 3)\n",
    "        ratio: float, percentage of points to occlude (0.0-1.0)\n",
    "        mode: str, 'random', 'region', or 'semantic'\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        corrupted_points: np.ndarray, shape (N, 3)\n",
    "        \"\"\"\n",
    "        num_points = points.shape[0]\n",
    "        num_to_occlude = int(num_points * ratio)\n",
    "        \n",
    "        if mode == 'random':\n",
    "            # Random occlusion\n",
    "            mask = np.ones(num_points, dtype=bool)\n",
    "            indices = np.random.choice(num_points, num_to_occlude, replace=False)\n",
    "            mask[indices] = False\n",
    "            return points[mask]\n",
    "        \n",
    "        elif mode == 'region':\n",
    "            # Region-based occlusion\n",
    "            center = np.random.uniform(-0.5, 0.5, size=3)\n",
    "            radius = np.random.uniform(0.2, 0.5)\n",
    "            \n",
    "            # Calculate distances to the center\n",
    "            distances = np.linalg.norm(points - center, axis=1)\n",
    "            \n",
    "            # Keep points outside the sphere\n",
    "            mask = distances > radius\n",
    "            return points[mask]\n",
    "        \n",
    "        elif mode == 'semantic':\n",
    "            # Semantic occlusion (simplified - just occludes one side)\n",
    "            # In real implementation, this would target specific semantic parts\n",
    "            dimension = np.random.randint(0, 3)  # Choose x, y, or z\n",
    "            threshold = np.median(points[:, dimension])\n",
    "            mask = points[:, dimension] > threshold\n",
    "            return points[mask]\n",
    "        \n",
    "        return points\n",
    "\n",
    "def prepare_dataloaders(dataset_path, batch_size=32, num_points=1024, num_workers=4):\n",
    "    \"\"\"\n",
    "    Prepare train and test data loaders\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_path: str, path to ModelNet40 dataset\n",
    "    batch_size: int, batch size\n",
    "    num_points: int, number of points per sample\n",
    "    num_workers: int, number of dataloader workers\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    train_loader: DataLoader for training data\n",
    "    test_loader: DataLoader for test data\n",
    "    \"\"\"\n",
    "    # Create datasets\n",
    "    train_dataset = ModelNet40Dataset(\n",
    "        root_dir=dataset_path,\n",
    "        split='train',\n",
    "        num_points=num_points,\n",
    "        random_rotation=True,\n",
    "        class_balance=True\n",
    "    )\n",
    "    \n",
    "    test_dataset = ModelNet40Dataset(\n",
    "        root_dir=dataset_path,\n",
    "        split='test',\n",
    "        num_points=num_points,\n",
    "        random_rotation=False,\n",
    "        class_balance=False\n",
    "    )\n",
    "    \n",
    "    # Create weighted sampler for class balancing\n",
    "    if train_dataset.weights is not None:\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=train_dataset.sample_weights,\n",
    "            num_samples=len(train_dataset),\n",
    "            replacement=True\n",
    "        )\n",
    "    else:\n",
    "        sampler = None\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def get_corrupted_dataset(dataset, corruption_type, severity):\n",
    "    \"\"\"\n",
    "    Create a corrupted version of a dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset: Dataset object\n",
    "    corruption_type: str, type of corruption\n",
    "    severity: int or float, severity level\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    corrupted_dataset: Dataset with corruption applied\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataset\n",
    "    corrupted_dataset = copy.deepcopy(dataset)\n",
    "    \n",
    "    # Define corruption parameters based on severity (1-5 scale)\n",
    "    if corruption_type == 'gaussian_noise':\n",
    "        param = {1: 0.01, 2: 0.02, 3: 0.03, 4: 0.04, 5: 0.05}[severity]\n",
    "        transform = lambda x: PointCloudCorruptor.add_gaussian_noise(x, sigma=param)\n",
    "    \n",
    "    elif corruption_type == 'snow':\n",
    "        density = {1: 0.05, 2: 0.1, 3: 0.15, 4: 0.2, 5: 0.3}[severity]\n",
    "        transform = lambda x: PointCloudCorruptor.add_snow(x, density=density)\n",
    "    \n",
    "    elif corruption_type == 'rain':\n",
    "        density = {1: 0.05, 2: 0.1, 3: 0.15, 4: 0.2, 5: 0.3}[severity]\n",
    "        transform = lambda x: PointCloudCorruptor.add_rain(x, density=density)\n",
    "    \n",
    "    elif corruption_type == 'fog':\n",
    "        density = {1: 0.05, 2: 0.1, 3: 0.2, 4: 0.3, 5: 0.4}[severity]\n",
    "        transform = lambda x: PointCloudCorruptor.add_fog(x, density=density)\n",
    "    \n",
    "    elif corruption_type == 'depth_noise':\n",
    "        param = {1: 0.01, 2: 0.02, 3: 0.04, 4: 0.06, 5: 0.1}[severity]\n",
    "        transform = lambda x: PointCloudCorruptor.add_depth_noise(x, k=param)\n",
    "    \n",
    "    elif corruption_type == 'occlusion':\n",
    "        ratio = {1: 0.1, 2: 0.15, 3: 0.2, 4: 0.25, 5: 0.3}[severity]\n",
    "        transform = lambda x: PointCloudCorruptor.add_occlusion(x, ratio=ratio)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported corruption type: {corruption_type}\")\n",
    "    \n",
    "    # Set the transform in the corrupted dataset\n",
    "    corrupted_dataset.transform = transform\n",
    "    \n",
    "    return corrupted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PointCloudAttacker:\n",
    "    def __init__(self, model, device=None):\n",
    "        \"\"\"\n",
    "        Class for implementing various adversarial attacks on point cloud models\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model: torch.nn.Module, the target model to attack\n",
    "        device: torch.device, device to perform computations on\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    # ======== White-box Attacks ========\n",
    "    \n",
    "    def fgsm_attack(self, points, labels, epsilon=0.03):\n",
    "        \"\"\"\n",
    "        Fast Gradient Sign Method attack\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: torch.Tensor of shape (B, N, 3) or (B, 3, N)\n",
    "        labels: torch.Tensor of shape (B,)\n",
    "        epsilon: float, attack strength\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        perturbed_points: torch.Tensor, adversarial examples\n",
    "        \"\"\"\n",
    "        # Clone the input and make sure it requires grad\n",
    "        points_format = 'channels_last' if points.shape[1] == 3 and len(points.shape) == 3 else 'channels_first'\n",
    "        if points_format == 'channels_first':\n",
    "            x = points.clone().detach().requires_grad_(True)\n",
    "        else:\n",
    "            x = points.clone().detach().transpose(2, 1).requires_grad_(True)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Generate perturbation\n",
    "        data_grad = x.grad.data\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        \n",
    "        # Create perturbed data\n",
    "        perturbed_points = x + epsilon * sign_data_grad\n",
    "        \n",
    "        # Project perturbations to keep points within original bounds\n",
    "        # Assuming original points are normalized to unit sphere\n",
    "        if points_format == 'channels_last':\n",
    "            return perturbed_points.detach().transpose(2, 1)\n",
    "        return perturbed_points.detach()\n",
    "    \n",
    "    def pgd_attack(self, points, labels, epsilon=0.03, alpha=None, num_iter=20):\n",
    "        \"\"\"\n",
    "        Projected Gradient Descent attack\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: torch.Tensor of shape (B, N, 3) or (B, 3, N)\n",
    "        labels: torch.Tensor of shape (B,)\n",
    "        epsilon: float, attack strength\n",
    "        alpha: float, step size (if None, will be set to epsilon/4)\n",
    "        num_iter: int, number of iterations\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        perturbed_points: torch.Tensor, adversarial examples\n",
    "        \"\"\"\n",
    "        if alpha is None:\n",
    "            alpha = epsilon / 4\n",
    "            \n",
    "        points_format = 'channels_last' if points.shape[1] == 3 and len(points.shape) == 3 else 'channels_first'\n",
    "        if points_format == 'channels_last':\n",
    "            original_points = points.clone().detach().transpose(2, 1)\n",
    "            perturbed_points = original_points.clone().detach().requires_grad_(True)\n",
    "        else:\n",
    "            original_points = points.clone().detach()\n",
    "            perturbed_points = original_points.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            # Forward pass\n",
    "            outputs = self.model(perturbed_points)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.model.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update points\n",
    "            with torch.no_grad():\n",
    "                perturbation = alpha * perturbed_points.grad.sign()\n",
    "                perturbed_points = perturbed_points + perturbation\n",
    "                \n",
    "                # Project back to epsilon ball\n",
    "                delta = perturbed_points - original_points\n",
    "                delta = torch.clamp(delta, -epsilon, epsilon)\n",
    "                perturbed_points = original_points + delta\n",
    "                \n",
    "                # Project to unit sphere if needed (optional)\n",
    "                # norm = torch.norm(perturbed_points, dim=1, keepdim=True)\n",
    "                # perturbed_points = perturbed_points / torch.max(norm, torch.ones_like(norm))\n",
    "            \n",
    "            # Reset gradients\n",
    "            if i < num_iter - 1:\n",
    "                perturbed_points.requires_grad_(True)\n",
    "        \n",
    "        if points_format == 'channels_last':\n",
    "            return perturbed_points.detach().transpose(2, 1)\n",
    "        return perturbed_points.detach()\n",
    "    \n",
    "    def cw_attack(self, points, labels, confidence=0, lr=0.01, num_iter=100):\n",
    "        \"\"\"\n",
    "        Carlini & Wagner attack\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: torch.Tensor of shape (B, N, 3) or (B, 3, N)\n",
    "        labels: torch.Tensor of shape (B,)\n",
    "        confidence: float, confidence parameter κ\n",
    "        lr: float, learning rate\n",
    "        num_iter: int, number of iterations\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        perturbed_points: torch.Tensor, adversarial examples\n",
    "        \"\"\"\n",
    "        points_format = 'channels_last' if points.shape[1] == 3 and len(points.shape) == 3 else 'channels_first'\n",
    "        if points_format == 'channels_last':\n",
    "            original_points = points.clone().detach().transpose(2, 1)\n",
    "        else:\n",
    "            original_points = points.clone().detach()\n",
    "            \n",
    "        # Initialize perturbation\n",
    "        delta = torch.zeros_like(original_points, requires_grad=True, device=self.device)\n",
    "        optimizer = torch.optim.Adam([delta], lr=lr)\n",
    "        \n",
    "        batch_size = points.shape[0]\n",
    "        target_labels = labels  # For untargeted attack, we just use the original labels\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Apply perturbation\n",
    "            perturbed_points = original_points + delta\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(perturbed_points)\n",
    "            \n",
    "            # CW loss: maximize the difference between target and highest non-target class\n",
    "            target_values = outputs.gather(1, target_labels.unsqueeze(1)).squeeze(1)\n",
    "            other_values = outputs.clone()\n",
    "            other_values.scatter_(1, target_labels.unsqueeze(1), -float('inf'))\n",
    "            other_values = other_values.max(dim=1)[0]\n",
    "            \n",
    "            # Loss with confidence parameter κ\n",
    "            loss = (other_values - target_values + confidence).clamp(min=0).mean()\n",
    "            \n",
    "            # Add regularization term for perturbation magnitude\n",
    "            loss += 0.01 * torch.norm(delta, dim=[1, 2]).mean()\n",
    "            \n",
    "            # Backward and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        perturbed_points = (original_points + delta).detach()\n",
    "        if points_format == 'channels_last':\n",
    "            return perturbed_points.transpose(2, 1)\n",
    "        return perturbed_points\n",
    "    \n",
    "    # ======== Black-box Attacks ========\n",
    "    \n",
    "    def transfer_attack(self, points, labels, surrogate_model, attack_type='pgd', **attack_params):\n",
    "        \"\"\"\n",
    "        Transfer attack using a surrogate model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: torch.Tensor of shape (B, N, 3) or (B, 3, N)\n",
    "        labels: torch.Tensor of shape (B,)\n",
    "        surrogate_model: torch.nn.Module, surrogate model to generate adversarial examples\n",
    "        attack_type: str, type of attack to use ('fgsm', 'pgd', 'cw')\n",
    "        attack_params: dict, parameters for the attack\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        perturbed_points: torch.Tensor, adversarial examples\n",
    "        \"\"\"\n",
    "        # Save original model\n",
    "        original_model = self.model\n",
    "        \n",
    "        # Set surrogate model for attack generation\n",
    "        self.model = surrogate_model\n",
    "        \n",
    "        # Generate adversarial examples\n",
    "        if attack_type == 'fgsm':\n",
    "            perturbed_points = self.fgsm_attack(points, labels, **attack_params)\n",
    "        elif attack_type == 'pgd':\n",
    "            perturbed_points = self.pgd_attack(points, labels, **attack_params)\n",
    "        elif attack_type == 'cw':\n",
    "            perturbed_points = self.cw_attack(points, labels, **attack_params)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported attack type: {attack_type}\")\n",
    "        \n",
    "        # Restore original model\n",
    "        self.model = original_model\n",
    "        \n",
    "        return perturbed_points\n",
    "    \n",
    "    # ======== Point Cloud-Specific Attacks ========\n",
    "    \n",
    "    def point_perturbation_attack(self, points, labels, max_displacement=0.05, num_iter=50, lr=0.01):\n",
    "        \"\"\"\n",
    "        Point perturbation attack with maximum displacement constraints\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: torch.Tensor of shape (B, N, 3) or (B, 3, N)\n",
    "        labels: torch.Tensor of shape (B,)\n",
    "        max_displacement: float, maximum displacement per point\n",
    "        num_iter: int, number of iterations\n",
    "        lr: float, learning rate\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        perturbed_points: torch.Tensor, adversarial examples\n",
    "        \"\"\"\n",
    "        points_format = 'channels_last' if points.shape[1] == 3 and len(points.shape) == 3 else 'channels_first'\n",
    "        if points_format == 'channels_last':\n",
    "            original_points = points.clone().detach().transpose(2, 1)\n",
    "        else:\n",
    "            original_points = points.clone().detach()\n",
    "            \n",
    "        # Initialize perturbation\n",
    "        delta = torch.zeros_like(original_points, requires_grad=True, device=self.device)\n",
    "        optimizer = torch.optim.Adam([delta], lr=lr)\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Apply perturbation with constraints\n",
    "            delta_clamped = torch.clamp(delta, -max_displacement, max_displacement)\n",
    "            perturbed_points = original_points + delta_clamped\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(perturbed_points)\n",
    "            \n",
    "            # Use cross-entropy loss for untargeted attack\n",
    "            loss = -torch.nn.functional.cross_entropy(outputs, labels)\n",
    "            \n",
    "            # Backward and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Final clamping\n",
    "        delta_clamped = torch.clamp(delta, -max_displacement, max_displacement)\n",
    "        perturbed_points = (original_points + delta_clamped).detach()\n",
    "        \n",
    "        if points_format == 'channels_last':\n",
    "            return perturbed_points.transpose(2, 1)\n",
    "        return perturbed_points\n",
    "    \n",
    "    def point_addition_removal(self, points, labels, ratio=0.1, mode='removal'):\n",
    "        \"\"\"\n",
    "        Point addition or removal attack\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        points: torch.Tensor of shape (B, N, 3) or (B, 3, N)\n",
    "        labels: torch.Tensor of shape (B,)\n",
    "        ratio: float, percentage of points to add/remove\n",
    "        mode: str, 'addition' or 'removal'\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        perturbed_points: torch.Tensor, adversarial examples\n",
    "        \"\"\"\n",
    "        points_format = 'channels_last' if points.shape[1] == 3 and len(points.shape) == 3 else 'channels_first'\n",
    "        if points_format == 'channels_last':\n",
    "            # Points are in shape [B, N, 3]\n",
    "            B, N, C = points.shape\n",
    "            points_to_process = points.clone()\n",
    "        else:\n",
    "            # Points are in shape [B, 3, N]\n",
    "            B, C, N = points.shape\n",
    "            points_to_process = points.clone().transpose(2, 1)\n",
    "            \n",
    "        perturbed_points = []\n",
    "        \n",
    "        for i in range(B):\n",
    "            point_cloud = points_to_process[i]  # [N, 3]\n",
    "            \n",
    "            if mode == 'removal':\n",
    "                # Remove points\n",
    "                num_to_remove = int(N * ratio)\n",
    "                \n",
    "                # Try to identify critical points (can be more sophisticated)\n",
    "                # For now, just randomly remove points\n",
    "                indices = torch.randperm(N)[:N-num_to_remove]\n",
    "                perturbed_cloud = point_cloud[indices]\n",
    "                \n",
    "                # Pad back to original size by duplicating existing points\n",
    "                if len(perturbed_cloud) < N:\n",
    "                    pad_indices = torch.randint(0, len(perturbed_cloud), (N - len(perturbed_cloud),))\n",
    "                    padding = perturbed_cloud[pad_indices]\n",
    "                    perturbed_cloud = torch.cat([perturbed_cloud, padding], dim=0)\n",
    "                \n",
    "            elif mode == 'addition':\n",
    "                # Add points\n",
    "                num_to_add = int(N * ratio)\n",
    "                \n",
    "                # Create new points (could be more sophisticated)\n",
    "                # For now, add noise to existing points\n",
    "                indices = torch.randint(0, N, (num_to_add,))\n",
    "                new_points = point_cloud[indices] + torch.randn_like(point_cloud[indices]) * 0.1\n",
    "                \n",
    "                # Remove some original points to keep the total constant\n",
    "                keep_indices = torch.randperm(N)[:N-num_to_add]\n",
    "                perturbed_cloud = torch.cat([point_cloud[keep_indices], new_points], dim=0)\n",
    "                \n",
    "            perturbed_points.append(perturbed_cloud)\n",
    "            \n",
    "        perturbed_points = torch.stack(perturbed_points, dim=0)\n",
    "        \n",
    "        if points_format == 'channels_first':\n",
    "            return perturbed_points.transpose(2, 1)\n",
    "        return perturbed_points\n",
    "    \n",
    "    # ======== Evaluation Metrics ========\n",
    "    \n",
    "    @staticmethod\n",
    "    def chamfer_distance(x, y):\n",
    "        \"\"\"\n",
    "        Calculate Chamfer distance between two point clouds\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x: torch.Tensor of shape (B, N, 3)\n",
    "        y: torch.Tensor of shape (B, M, 3)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        distance: torch.Tensor of shape (B,)\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(2)  # (B, N, 1, 3)\n",
    "        y = y.unsqueeze(1)  # (B, 1, M, 3)\n",
    "        \n",
    "        # Calculate pairwise distances\n",
    "        dist = torch.sum((x - y) ** 2, dim=3)  # (B, N, M)\n",
    "        \n",
    "        # Find minimum distances\n",
    "        min_dist_xy = torch.min(dist, dim=2)[0]  # (B, N)\n",
    "        min_dist_yx = torch.min(dist, dim=1)[0]  # (B, M)\n",
    "        \n",
    "        # Calculate Chamfer distance\n",
    "        chamfer_dist = torch.mean(min_dist_xy, dim=1) + torch.mean(min_dist_yx, dim=1)\n",
    "        \n",
    "        return chamfer_dist\n",
    "    \n",
    "    @staticmethod\n",
    "    def hausdorff_distance(x, y):\n",
    "        \"\"\"\n",
    "        Calculate Hausdorff distance between two point clouds\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x: torch.Tensor of shape (B, N, 3)\n",
    "        y: torch.Tensor of shape (B, M, 3)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        distance: torch.Tensor of shape (B,)\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(2)  # (B, N, 1, 3)\n",
    "        y = y.unsqueeze(1)  # (B, 1, M, 3)\n",
    "        \n",
    "        # Calculate pairwise distances\n",
    "        dist = torch.sum((x - y) ** 2, dim=3)  # (B, N, M)\n",
    "        \n",
    "        # Find minimum distances\n",
    "        min_dist_xy = torch.min(dist, dim=2)[0]  # (B, N)\n",
    "        min_dist_yx = torch.min(dist, dim=1)[0]  # (B, M)\n",
    "        \n",
    "        # Calculate Hausdorff distance\n",
    "        hausdorff_dist = torch.max(torch.max(min_dist_xy, dim=1)[0], torch.max(min_dist_yx, dim=1)[0])\n",
    "        \n",
    "        return hausdorff_dist\n",
    "\n",
    "class AdversarialEvaluator:\n",
    "    def __init__(self, model_list, device=None):\n",
    "        \"\"\"\n",
    "        Class for evaluating model robustness against adversarial attacks\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_list: dict, dictionary of models to evaluate {name: model}\n",
    "        device: torch.device, device to perform computations on\n",
    "        \"\"\"\n",
    "        self.models = model_list\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.attackers = {name: PointCloudAttacker(model, self.device) for name, model in self.models.items()}\n",
    "        \n",
    "    def evaluate_whitebox_attacks(self, dataloader, attack_params=None):\n",
    "        \"\"\"\n",
    "        Evaluate models against white-box attacks\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataloader: torch.utils.data.DataLoader, test data\n",
    "        attack_params: dict, parameters for different attacks\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, evaluation results\n",
    "        \"\"\"\n",
    "        if attack_params is None:\n",
    "            attack_params = {\n",
    "                'fgsm': {'epsilon': [0.01, 0.03, 0.05, 0.1]},\n",
    "                'pgd': {\n",
    "                    'epsilon': [0.03, 0.05],\n",
    "                    'num_iter': [10, 20, 50],\n",
    "                    'alpha': None  # Will be set to epsilon/4\n",
    "                },\n",
    "                'cw': {'confidence': [0, 20, 40], 'num_iter': 100}\n",
    "            }\n",
    "            \n",
    "        results = {}\n",
    "        \n",
    "        # Evaluate each model\n",
    "        for model_name, attacker in self.attackers.items():\n",
    "            model_results = {}\n",
    "            model = self.models[model_name]\n",
    "            model.eval()\n",
    "            \n",
    "            print(f\"Evaluating {model_name} against white-box attacks...\")\n",
    "            \n",
    "            # FGSM attacks\n",
    "            for eps in attack_params['fgsm']['epsilon']:\n",
    "                clean_correct = 0\n",
    "                adv_correct = 0\n",
    "                total = 0\n",
    "                chamfer_dists = []\n",
    "                hausdorff_dists = []\n",
    "                \n",
    "                for data, labels in tqdm(dataloader, desc=f\"FGSM ε={eps}\"):\n",
    "                    data, labels = data.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Calculate clean accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        clean_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # Generate adversarial examples\n",
    "                    perturbed_data = attacker.fgsm_attack(data, labels, epsilon=eps)\n",
    "                    \n",
    "                    # Calculate adversarial accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(perturbed_data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        adv_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # Calculate distances\n",
    "                    if data.shape[1] != 3:  # If data is in shape [B, 3, N]\n",
    "                        data_reshaped = data.transpose(2, 1)\n",
    "                        perturbed_reshaped = perturbed_data.transpose(2, 1)\n",
    "                    else:\n",
    "                        data_reshaped = data\n",
    "                        perturbed_reshaped = perturbed_data\n",
    "                        \n",
    "                    chamfer_dists.append(attacker.chamfer_distance(data_reshaped, perturbed_reshaped).mean().item())\n",
    "                    hausdorff_dists.append(attacker.hausdorff_distance(data_reshaped, perturbed_reshaped).mean().item())\n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                \n",
    "                model_results[f'fgsm_eps_{eps}'] = {\n",
    "                    'clean_acc': clean_correct / total,\n",
    "                    'adv_acc': adv_correct / total,\n",
    "                    'chamfer_dist': np.mean(chamfer_dists),\n",
    "                    'hausdorff_dist': np.mean(hausdorff_dists)\n",
    "                }\n",
    "                \n",
    "            # PGD attacks\n",
    "            for eps in attack_params['pgd']['epsilon']:\n",
    "                for iters in attack_params['pgd']['num_iter']:\n",
    "                    alpha = eps / 4  # Default step size\n",
    "                    \n",
    "                    clean_correct = 0\n",
    "                    adv_correct = 0\n",
    "                    total = 0\n",
    "                    chamfer_dists = []\n",
    "                    hausdorff_dists = []\n",
    "                    \n",
    "                    for data, labels in tqdm(dataloader, desc=f\"PGD ε={eps}, iter={iters}\"):\n",
    "                        data, labels = data.to(self.device), labels.to(self.device)\n",
    "                        \n",
    "                        # Calculate clean accuracy\n",
    "                        with torch.no_grad():\n",
    "                            outputs = model(data)\n",
    "                            _, predicted = outputs.max(1)\n",
    "                            clean_correct += predicted.eq(labels).sum().item()\n",
    "                        \n",
    "                        # Generate adversarial examples\n",
    "                        perturbed_data = attacker.pgd_attack(data, labels, epsilon=eps, alpha=alpha, num_iter=iters)\n",
    "                        \n",
    "                        # Calculate adversarial accuracy\n",
    "                        with torch.no_grad():\n",
    "                            outputs = model(perturbed_data)\n",
    "                            _, predicted = outputs.max(1)\n",
    "                            adv_correct += predicted.eq(labels).sum().item()\n",
    "                        \n",
    "                        # Calculate distances\n",
    "                        if data.shape[1] != 3:  # If data is in shape [B, 3, N]\n",
    "                            data_reshaped = data.transpose(2, 1)\n",
    "                            perturbed_reshaped = perturbed_data.transpose(2, 1)\n",
    "                        else:\n",
    "                            data_reshaped = data\n",
    "                            perturbed_reshaped = perturbed_data\n",
    "                            \n",
    "                        chamfer_dists.append(attacker.chamfer_distance(data_reshaped, perturbed_reshaped).mean().item())\n",
    "                        hausdorff_dists.append(attacker.hausdorff_distance(data_reshaped, perturbed_reshaped).mean().item())\n",
    "                        \n",
    "                        total += labels.size(0)\n",
    "                    \n",
    "                    model_results[f'pgd_eps_{eps}_iter_{iters}'] = {\n",
    "                        'clean_acc': clean_correct / total,\n",
    "                        'adv_acc': adv_correct / total,\n",
    "                        'chamfer_dist': np.mean(chamfer_dists),\n",
    "                        'hausdorff_dist': np.mean(hausdorff_dists)\n",
    "                    }\n",
    "            \n",
    "            # C&W attacks - more computation intensive, let's use a subset of the data\n",
    "            for conf in attack_params['cw']['confidence']:\n",
    "                clean_correct = 0\n",
    "                adv_correct = 0\n",
    "                total = 0\n",
    "                chamfer_dists = []\n",
    "                hausdorff_dists = []\n",
    "                \n",
    "                # Limit to first 200 samples for C&W due to computational cost\n",
    "                sample_count = 0\n",
    "                for data, labels in tqdm(dataloader, desc=f\"C&W κ={conf}\"):\n",
    "                    if sample_count >= 200:\n",
    "                        break\n",
    "                        \n",
    "                    data, labels = data.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Calculate clean accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        clean_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # Generate adversarial examples\n",
    "                    perturbed_data = attacker.cw_attack(data, labels, confidence=conf, num_iter=attack_params['cw']['num_iter'])\n",
    "                    \n",
    "                    # Calculate adversarial accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(perturbed_data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        adv_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # Calculate distances\n",
    "                    if data.shape[1] != 3:  # If data is in shape [B, 3, N]\n",
    "                        data_reshaped = data.transpose(2, 1)\n",
    "                        perturbed_reshaped = perturbed_data.transpose(2, 1)\n",
    "                    else:\n",
    "                        data_reshaped = data\n",
    "                        perturbed_reshaped = perturbed_data\n",
    "                        \n",
    "                    chamfer_dists.append(attacker.chamfer_distance(data_reshaped, perturbed_reshaped).mean().item())\n",
    "                    hausdorff_dists.append(attacker.hausdorff_distance(data_reshaped, perturbed_reshaped).mean().item())\n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                    sample_count += labels.size(0)\n",
    "                \n",
    "                if total > 0:\n",
    "                    model_results[f'cw_conf_{conf}'] = {\n",
    "                        'clean_acc': clean_correct / total,\n",
    "                        'adv_acc': adv_correct / total,\n",
    "                        'chamfer_dist': np.mean(chamfer_dists),\n",
    "                        'hausdorff_dist': np.mean(hausdorff_dists)\n",
    "                    }\n",
    "            \n",
    "            results[model_name] = model_results\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def evaluate_point_specific_attacks(self, dataloader):\n",
    "        \"\"\"\n",
    "        Evaluate models against point cloud-specific attacks\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataloader: torch.utils.data.DataLoader, test data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, evaluation results\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Define attack parameters\n",
    "        perturbation_max = [0.02, 0.05, 0.1]\n",
    "        removal_ratios = [0.05, 0.1, 0.15]\n",
    "        \n",
    "        # Evaluate each model\n",
    "        for model_name, attacker in self.attackers.items():\n",
    "            model_results = {}\n",
    "            model = self.models[model_name]\n",
    "            model.eval()\n",
    "            \n",
    "            print(f\"Evaluating {model_name} against point cloud-specific attacks...\")\n",
    "            \n",
    "            # Point perturbation attacks\n",
    "            for max_disp in perturbation_max:\n",
    "                clean_correct = 0\n",
    "                adv_correct = 0\n",
    "                total = 0\n",
    "                chamfer_dists = []\n",
    "                \n",
    "                for data, labels in tqdm(dataloader, desc=f\"Perturbation max={max_disp}\"):\n",
    "                    data, labels = data.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Calculate clean accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        clean_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # Generate adversarial examples\n",
    "                    perturbed_data = attacker.point_perturbation_attack(data, labels, max_displacement=max_disp)\n",
    "                    \n",
    "                    # Calculate adversarial accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(perturbed_data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        adv_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # Calculate Chamfer distance\n",
    "                    if data.shape[1] != 3:  # If data is in shape [B, 3, N]\n",
    "                        data_reshaped = data.transpose(2, 1)\n",
    "                        perturbed_reshaped = perturbed_data.transpose(2, 1)\n",
    "                    else:\n",
    "                        data_reshaped = data\n",
    "                        perturbed_reshaped = perturbed_data\n",
    "                        \n",
    "                    chamfer_dists.append(attacker.chamfer_distance(data_reshaped, perturbed_reshaped).mean().item())\n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                \n",
    "                model_results[f'perturb_max_{max_disp}'] = {\n",
    "                    'clean_acc': clean_correct / total,\n",
    "                    'adv_acc': adv_correct / total,\n",
    "                    'chamfer_dist': np.mean(chamfer_dists)\n",
    "                }\n",
    "            \n",
    "            # Point removal attacks\n",
    "            for ratio in removal_ratios:\n",
    "                clean_correct = 0\n",
    "                adv_correct = 0\n",
    "                total = 0\n",
    "                \n",
    "                for data, labels in tqdm(dataloader, desc=f\"Removal ratio={ratio}\"):\n",
    "                    data, labels = data.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Calculate clean accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        clean_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # Generate adversarial examples\n",
    "                    perturbed_data = attacker.point_addition_removal(data, labels, ratio=ratio, mode='removal')\n",
    "                    \n",
    "                    # Calculate adversarial accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(perturbed_data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        adv_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                \n",
    "                model_results[f'removal_ratio_{ratio}'] = {\n",
    "                    'clean_acc': clean_correct / total,\n",
    "                    'adv_acc': adv_correct / total\n",
    "                }\n",
    "            \n",
    "            results[model_name] = model_results\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def cross_validate_attacks(self, dataset, attack_type, folds=5, **attack_params):\n",
    "        \"\"\"\n",
    "        Perform cross-validation for adversarial attacks\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataset: torch.utils.data.Dataset, full dataset\n",
    "        attack_type: str, attack type to evaluate\n",
    "        folds: int, number of folds for cross-validation\n",
    "        attack_params: dict, parameters for the attack\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        cv_results: dict, cross-validation results\n",
    "        \"\"\"\n",
    "        # Define fold sizes\n",
    "        dataset_size = len(dataset)\n",
    "        fold_size = dataset_size // folds\n",
    "        \n",
    "        cv_results = {model_name: [] for model_name in self.models.keys()}\n",
    "        \n",
    "        for fold in range(folds):\n",
    "            print(f\"Cross-validation fold {fold+1}/{folds}\")\n",
    "            \n",
    "            # Split dataset\n",
    "            test_indices = list(range(fold * fold_size, (fold + 1) * fold_size))\n",
    "            train_indices = list(set(range(dataset_size)) - set(test_indices))\n",
    "            \n",
    "            test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "            test_loader = torch.utils.data.DataLoader(dataset, batch_size=32, sampler=test_sampler)\n",
    "            \n",
    "            # Evaluate each model\n",
    "            for model_name, model in self.models.items():\n",
    "                model.eval()\n",
    "                attacker = self.attackers[model_name]\n",
    "                \n",
    "                # Initialize attack function based on type\n",
    "                if attack_type == 'fgsm':\n",
    "                    attack_fn = attacker.fgsm_attack\n",
    "                elif attack_type == 'pgd':\n",
    "                    attack_fn = attacker.pgd_attack\n",
    "                elif attack_type == 'cw':\n",
    "                    attack_fn = attacker.cw_attack\n",
    "                elif attack_type == 'perturb':\n",
    "                    attack_fn = attacker.point_perturbation_attack\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported attack type for cross-validation: {attack_type}\")\n",
    "                \n",
    "                # Evaluate on test set\n",
    "                clean_correct = 0\n",
    "                adv_correct = 0\n",
    "                total = 0\n",
    "                \n",
    "                for data, labels in test_loader:\n",
    "                    data, labels = data.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Calculate clean accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        clean_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # Generate adversarial examples\n",
    "                    perturbed_data = attack_fn(data, labels, **attack_params)\n",
    "                    \n",
    "                    # Calculate adversarial accuracy\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(perturbed_data)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        adv_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                \n",
    "                fold_result = {\n",
    "                    'fold': fold,\n",
    "                    'clean_acc': clean_correct / total,\n",
    "                    'adv_acc': adv_correct / total\n",
    "                }\n",
    "                cv_results[model_name].append(fold_result)\n",
    "                \n",
    "        # Calculate mean and std across folds\n",
    "        for model_name in cv_results:\n",
    "            clean_accs = [fold['clean_acc'] for fold in cv_results[model_name]]\n",
    "            adv_accs = [fold['adv_acc'] for fold in cv_results[model_name]]\n",
    "            \n",
    "            cv_results[model_name].append({\n",
    "                'mean_clean_acc': np.mean(clean_accs),\n",
    "                'std_clean_acc': np.std(clean_accs),\n",
    "                'mean_adv_acc': np.mean(adv_accs),\n",
    "                'std_adv_acc': np.std(adv_accs)\n",
    "            })\n",
    "            \n",
    "        return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EvaluationFramework:\n",
    "    def __init__(self, models, device=None, num_classes=40):\n",
    "        \"\"\"\n",
    "        Comprehensive evaluation framework for 3D point cloud models\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        models: dict, dictionary of models to evaluate {name: model}\n",
    "        device: torch.device, device to perform computations on\n",
    "        num_classes: int, number of classes in the dataset\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = None  # Should be set when evaluating with actual dataset\n",
    "        \n",
    "        # Move models to device\n",
    "        for name, model in self.models.items():\n",
    "            model.to(self.device)\n",
    "    \n",
    "    # ======== Performance Metrics ========\n",
    "    \n",
    "    def evaluate_classification_performance(self, dataloader, verbose=True):\n",
    "        \"\"\"\n",
    "        Evaluate classification performance metrics\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataloader: DataLoader, test dataloader\n",
    "        verbose: bool, whether to print results\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, metrics for each model\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            model.eval()\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for points, labels in tqdm(dataloader, desc=f\"Evaluating {name}\", disable=not verbose):\n",
    "                    points, labels = points.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Model prediction\n",
    "                    logits = model(points)\n",
    "                    \n",
    "                    # Store predictions and labels\n",
    "                    _, preds = torch.topk(logits, k=5, dim=1)\n",
    "                    all_preds.append(preds.cpu().numpy())\n",
    "                    all_labels.append(labels.cpu().numpy())\n",
    "            \n",
    "            # Concatenate results\n",
    "            all_preds = np.concatenate(all_preds, axis=0)\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            top1_acc = (all_preds[:, 0] == all_labels).mean()\n",
    "            top5_acc = np.any(all_preds == all_labels.reshape(-1, 1), axis=1).mean()\n",
    "            \n",
    "            # Per-class metrics\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels, all_preds[:, 0], average=None, labels=range(self.num_classes)\n",
    "            )\n",
    "            \n",
    "            # Average metrics\n",
    "            avg_precision, avg_recall, avg_f1, _ = precision_recall_fscore_support(\n",
    "                all_labels, all_preds[:, 0], average='macro'\n",
    "            )\n",
    "            \n",
    "            # Confusion matrix\n",
    "            conf_mat = confusion_matrix(all_labels, all_preds[:, 0], labels=range(self.num_classes))\n",
    "            \n",
    "            # Store results\n",
    "            results[name] = {\n",
    "                'top1_accuracy': top1_acc,\n",
    "                'top5_accuracy': top5_acc,\n",
    "                'per_class_precision': precision,\n",
    "                'per_class_recall': recall,\n",
    "                'per_class_f1': f1,\n",
    "                'avg_precision': avg_precision,\n",
    "                'avg_recall': avg_recall,\n",
    "                'avg_f1': avg_f1,\n",
    "                'confusion_matrix': conf_mat,\n",
    "                'all_preds': all_preds,\n",
    "                'all_labels': all_labels\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n{name} Classification Results:\")\n",
    "                print(f\"Top-1 Accuracy: {top1_acc:.4f}\")\n",
    "                print(f\"Top-5 Accuracy: {top5_acc:.4f}\")\n",
    "                print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "                print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "                print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
    "                \n",
    "        return results\n",
    "    \n",
    "    def evaluate_robustness_metrics(self, clean_dataloader, corrupted_loaders, verbose=True):\n",
    "        \"\"\"\n",
    "        Evaluate robustness metrics across different corruptions\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        clean_dataloader: DataLoader, clean test data\n",
    "        corrupted_loaders: dict, {corruption_name: {severity: dataloader}}\n",
    "        verbose: bool, whether to print results\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, robustness metrics for each model\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Evaluate clean accuracy first\n",
    "        clean_results = self.evaluate_classification_performance(clean_dataloader, verbose=False)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            model.eval()\n",
    "            model_results = {\n",
    "                'clean_accuracy': clean_results[name]['top1_accuracy'],\n",
    "                'corruption_results': {}\n",
    "            }\n",
    "            \n",
    "            # Evaluate on each corruption type and severity\n",
    "            corruption_errors = []\n",
    "            \n",
    "            for corruption, severity_loaders in corrupted_loaders.items():\n",
    "                corruption_accs = []\n",
    "                \n",
    "                for severity, loader in severity_loaders.items():\n",
    "                    # Evaluate on corrupted data\n",
    "                    all_preds = []\n",
    "                    all_labels = []\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        for points, labels in loader:\n",
    "                            points, labels = points.to(self.device), labels.to(self.device)\n",
    "                            logits = model(points)\n",
    "                            preds = logits.argmax(dim=1)\n",
    "                            all_preds.append(preds.cpu().numpy())\n",
    "                            all_labels.append(labels.cpu().numpy())\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    all_preds = np.concatenate(all_preds, axis=0)\n",
    "                    all_labels = np.concatenate(all_labels, axis=0)\n",
    "                    accuracy = (all_preds == all_labels).mean()\n",
    "                    \n",
    "                    # Store results\n",
    "                    model_results['corruption_results'][(corruption, severity)] = {\n",
    "                        'accuracy': accuracy,\n",
    "                        'error': 1.0 - accuracy\n",
    "                    }\n",
    "                    \n",
    "                    corruption_accs.append(accuracy)\n",
    "                    corruption_errors.append(1.0 - accuracy)\n",
    "                \n",
    "                # Calculate clean-corrupted accuracy gap (CCAG) for this corruption\n",
    "                avg_corrupt_acc = np.mean(corruption_accs)\n",
    "                ccag = clean_results[name]['top1_accuracy'] - avg_corrupt_acc\n",
    "                \n",
    "                model_results['corruption_results'][corruption] = {\n",
    "                    'avg_accuracy': avg_corrupt_acc,\n",
    "                    'ccag': ccag\n",
    "                }\n",
    "            \n",
    "            # Calculate average corruption error (ACE)\n",
    "            ace = np.mean(corruption_errors)\n",
    "            \n",
    "            # Calculate effective robustness (ER) - relative to baseline performance\n",
    "            # This would typically compare to a baseline model, but for now we'll use relative to clean performance\n",
    "            er = clean_results[name]['top1_accuracy'] - ace\n",
    "            \n",
    "            # Calculate area under robustness curve (AURC)\n",
    "            # For simplicity, we'll calculate area under error vs corruption severity curve\n",
    "            aurc = np.trapz(corruption_errors) / len(corruption_errors)\n",
    "            \n",
    "            model_results['summary'] = {\n",
    "                'ace': ace,\n",
    "                'er': er,\n",
    "                'aurc': aurc\n",
    "            }\n",
    "            \n",
    "            results[name] = model_results\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n{name} Robustness Results:\")\n",
    "                print(f\"Clean Accuracy: {clean_results[name]['top1_accuracy']:.4f}\")\n",
    "                print(f\"Average Corruption Error (ACE): {ace:.4f}\")\n",
    "                print(f\"Effective Robustness (ER): {er:.4f}\")\n",
    "                print(f\"Area Under Robustness Curve (AURC): {aurc:.4f}\")\n",
    "                \n",
    "        return results\n",
    "    \n",
    "    def benchmark_efficiency(self, sample_input, num_runs=100, verbose=True):\n",
    "        \"\"\"\n",
    "        Benchmark the efficiency metrics of models\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        sample_input: torch.Tensor, sample input for models\n",
    "        num_runs: int, number of runs for time measurement\n",
    "        verbose: bool, whether to print results\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, efficiency metrics for each model\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        sample_input = sample_input.to(self.device)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            model.eval()\n",
    "            model_results = {}\n",
    "            \n",
    "            # Measure inference time\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                for _ in range(num_runs):\n",
    "                    _ = model(sample_input)\n",
    "            end_time = time.time()\n",
    "            avg_inference_time = (end_time - start_time) / num_runs\n",
    "            \n",
    "            # Measure memory consumption\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            torch.cuda.empty_cache()\n",
    "            with torch.no_grad():\n",
    "                _ = model(sample_input)\n",
    "            memory_usage = torch.cuda.max_memory_allocated() / (1024 ** 2)  # MB\n",
    "            \n",
    "            # Estimate FLOPs using PyTorch profiler\n",
    "            with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                         with_flops=True) as prof:\n",
    "                with record_function(\"model_inference\"):\n",
    "                    _ = model(sample_input)\n",
    "            \n",
    "            flops_estimate = sum(evt.flops for evt in prof.key_averages() if evt.flops > 0)\n",
    "            \n",
    "            model_results = {\n",
    "                'inference_time_ms': avg_inference_time * 1000,\n",
    "                'memory_usage_mb': memory_usage,\n",
    "                'estimated_flops': flops_estimate\n",
    "            }\n",
    "            \n",
    "            results[name] = model_results\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n{name} Efficiency Metrics:\")\n",
    "                print(f\"Inference Time: {avg_inference_time * 1000:.2f} ms\")\n",
    "                print(f\"Memory Usage: {memory_usage:.2f} MB\")\n",
    "                print(f\"Estimated FLOPs: {flops_estimate:.2e}\")\n",
    "                \n",
    "        return results\n",
    "    \n",
    "    # ======== Analysis Procedures ========\n",
    "    \n",
    "    def ablation_study(self, model_name, components, dataloader):\n",
    "        \"\"\"\n",
    "        Perform ablation study on model components\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model to ablate\n",
    "        components: list of tuples, (component_name, ablation_function)\n",
    "        dataloader: DataLoader, test data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, performance with each component ablated\n",
    "        \"\"\"\n",
    "        # Get original model\n",
    "        original_model = self.models[model_name]\n",
    "        original_state = copy.deepcopy(original_model.state_dict())\n",
    "        \n",
    "        # Evaluate original performance\n",
    "        original_performance = self.evaluate_classification_performance(\n",
    "            dataloader, verbose=False)[model_name]['top1_accuracy']\n",
    "        \n",
    "        results = {'original': original_performance}\n",
    "        \n",
    "        # Test each ablation\n",
    "        for component_name, ablation_fn in components:\n",
    "            # Apply ablation\n",
    "            ablation_fn(original_model)\n",
    "            \n",
    "            # Evaluate ablated model\n",
    "            ablated_performance = self.evaluate_classification_performance(\n",
    "                dataloader, verbose=False)[model_name]['top1_accuracy']\n",
    "            \n",
    "            # Restore original model\n",
    "            original_model.load_state_dict(original_state)\n",
    "            \n",
    "            # Store results\n",
    "            results[component_name] = ablated_performance\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def parameter_sensitivity_analysis(self, model_name, parameter_ranges, dataloader):\n",
    "        \"\"\"\n",
    "        Analyze sensitivity to critical parameters\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model to analyze\n",
    "        parameter_ranges: dict, {param_name: list of values}\n",
    "        dataloader: DataLoader, test data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, performance across parameter values\n",
    "        \"\"\"\n",
    "        # Get original model\n",
    "        original_model = self.models[model_name]\n",
    "        original_state = copy.deepcopy(original_model.state_dict())\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Test each parameter\n",
    "        for param_name, param_values in parameter_ranges.items():\n",
    "            param_results = []\n",
    "            \n",
    "            for value in param_values:\n",
    "                # Set parameter value (this would depend on model architecture)\n",
    "                # Example: setattr(original_model, param_name, value)\n",
    "                \n",
    "                # Evaluate model with this parameter value\n",
    "                performance = self.evaluate_classification_performance(\n",
    "                    dataloader, verbose=False)[model_name]['top1_accuracy']\n",
    "                param_results.append((value, performance))\n",
    "                \n",
    "                # Restore original model\n",
    "                original_model.load_state_dict(original_state)\n",
    "            \n",
    "            results[param_name] = param_results\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def attack_transferability_analysis(self, source_models, target_models, dataloader, attack_method, **attack_params):\n",
    "        \"\"\"\n",
    "        Analyze the transferability of adversarial attacks between models\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        source_models: list, names of models to generate attacks from\n",
    "        target_models: list, names of models to test attacks on\n",
    "        dataloader: DataLoader, test data\n",
    "        attack_method: function, attack method to use\n",
    "        attack_params: dict, parameters for the attack\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, transfer success rates between all model pairs\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for source_name in source_models:\n",
    "            source_model = self.models[source_name]\n",
    "            source_attacker = PointCloudAttacker(source_model, self.device)\n",
    "            \n",
    "            # Results for this source model\n",
    "            source_results = {}\n",
    "            \n",
    "            for target_name in target_models:\n",
    "                if source_name == target_name:\n",
    "                    continue  # Skip self-targeting\n",
    "                    \n",
    "                target_model = self.models[target_name]\n",
    "                target_model.eval()\n",
    "                \n",
    "                # Track performance\n",
    "                clean_correct = 0\n",
    "                adv_correct = 0\n",
    "                total = 0\n",
    "                \n",
    "                for points, labels in dataloader:\n",
    "                    points, labels = points.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Generate adversarial examples on source model\n",
    "                    adv_points = attack_method(source_attacker, points, labels, **attack_params)\n",
    "                    \n",
    "                    # Evaluate performance on target model\n",
    "                    with torch.no_grad():\n",
    "                        # Clean performance\n",
    "                        clean_outputs = target_model(points)\n",
    "                        clean_preds = clean_outputs.argmax(dim=1)\n",
    "                        clean_correct += (clean_preds == labels).sum().item()\n",
    "                        \n",
    "                        # Adversarial performance\n",
    "                        adv_outputs = target_model(adv_points)\n",
    "                        adv_preds = adv_outputs.argmax(dim=1)\n",
    "                        adv_correct += (adv_preds == labels).sum().item()\n",
    "                        \n",
    "                    total += labels.size(0)\n",
    "                \n",
    "                # Calculate transfer success rate\n",
    "                clean_acc = clean_correct / total\n",
    "                adv_acc = adv_correct / total\n",
    "                transfer_success_rate = (clean_acc - adv_acc) / clean_acc  # Normalized attack success\n",
    "                \n",
    "                source_results[target_name] = {\n",
    "                    'clean_accuracy': clean_acc,\n",
    "                    'adv_accuracy': adv_acc,\n",
    "                    'transfer_success_rate': transfer_success_rate\n",
    "                }\n",
    "                \n",
    "            results[source_name] = source_results\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def statistical_significance_testing(self, model1_name, model2_name, dataloader, num_bootstrap=1000):\n",
    "        \"\"\"\n",
    "        Perform statistical significance testing between two models\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model1_name: str, name of first model\n",
    "        model2_name: str, name of second model\n",
    "        dataloader: DataLoader, test data\n",
    "        num_bootstrap: int, number of bootstrap samples\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, statistical test results\n",
    "        \"\"\"\n",
    "        model1 = self.models[model1_name]\n",
    "        model2 = self.models[model2_name]\n",
    "        \n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "        \n",
    "        # Collect all predictions\n",
    "        all_labels = []\n",
    "        model1_preds = []\n",
    "        model2_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for points, labels in dataloader:\n",
    "                points, labels = points.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Model 1 predictions\n",
    "                outputs1 = model1(points)\n",
    "                preds1 = outputs1.argmax(dim=1)\n",
    "                \n",
    "                # Model 2 predictions\n",
    "                outputs2 = model2(points)\n",
    "                preds2 = outputs2.argmax(dim=1)\n",
    "                \n",
    "                # Store results\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "                model1_preds.append(preds1.cpu().numpy())\n",
    "                model2_preds.append(preds2.cpu().numpy())\n",
    "        \n",
    "        # Concatenate results\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        model1_preds = np.concatenate(model1_preds, axis=0)\n",
    "        model2_preds = np.concatenate(model2_preds, axis=0)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        model1_correct = (model1_preds == all_labels)\n",
    "        model2_correct = (model2_preds == all_labels)\n",
    "        \n",
    "        model1_acc = model1_correct.mean()\n",
    "        model2_acc = model2_correct.mean()\n",
    "        \n",
    "        # Paired t-test\n",
    "        t_stat, p_value = stats.ttest_rel(model1_correct, model2_correct)\n",
    "        \n",
    "        # Bootstrap confidence intervals\n",
    "        bootstrap_diffs = []\n",
    "        for _ in range(num_bootstrap):\n",
    "            indices = np.random.choice(len(all_labels), len(all_labels), replace=True)\n",
    "            model1_sample = model1_correct[indices].mean()\n",
    "            model2_sample = model2_correct[indices].mean()\n",
    "            bootstrap_diffs.append(model1_sample - model2_sample)\n",
    "            \n",
    "        bootstrap_diffs = np.array(bootstrap_diffs)\n",
    "        ci_lower = np.percentile(bootstrap_diffs, 2.5)\n",
    "        ci_upper = np.percentile(bootstrap_diffs, 97.5)\n",
    "        \n",
    "        results = {\n",
    "            f\"{model1_name}_accuracy\": model1_acc,\n",
    "            f\"{model2_name}_accuracy\": model2_acc,\n",
    "            'accuracy_diff': model1_acc - model2_acc,\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < 0.05,\n",
    "            'bootstrap_ci': (ci_lower, ci_upper),\n",
    "            'bootstrap_significant': (ci_lower > 0 or ci_upper < 0)  # CI doesn't contain 0\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # ======== Real-world Validation ========\n",
    "    \n",
    "    def synthetic_to_real_transfer(self, synthetic_loader, real_loader):\n",
    "        \"\"\"\n",
    "        Evaluate synthetic-to-real transfer performance\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        synthetic_loader: DataLoader, synthetic test data\n",
    "        real_loader: DataLoader, real-world test data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, performance comparison on synthetic and real data\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            model.eval()\n",
    "            \n",
    "            # Evaluate on synthetic data\n",
    "            synthetic_performance = self.evaluate_classification_performance(\n",
    "                synthetic_loader, verbose=False)[name]\n",
    "            \n",
    "            # Evaluate on real data\n",
    "            real_performance = self.evaluate_classification_performance(\n",
    "                real_loader, verbose=False)[name]\n",
    "            \n",
    "            # Calculate transfer gap\n",
    "            transfer_gap = synthetic_performance['top1_accuracy'] - real_performance['top1_accuracy']\n",
    "            \n",
    "            results[name] = {\n",
    "                'synthetic_accuracy': synthetic_performance['top1_accuracy'],\n",
    "                'real_accuracy': real_performance['top1_accuracy'],\n",
    "                'transfer_gap': transfer_gap\n",
    "            }\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    # ======== Visualization Methods ========\n",
    "    \n",
    "    def plot_confusion_matrix(self, model_name, results=None, figsize=(12, 10)):\n",
    "        \"\"\"\n",
    "        Plot confusion matrix for a model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model\n",
    "        results: dict, results from evaluate_classification_performance\n",
    "        figsize: tuple, figure size\n",
    "        \"\"\"\n",
    "        if results is None:\n",
    "            raise ValueError(\"Results dictionary must be provided\")\n",
    "            \n",
    "        if model_name not in results:\n",
    "            raise ValueError(f\"No results found for model {model_name}\")\n",
    "            \n",
    "        conf_mat = results[model_name]['confusion_matrix']\n",
    "        \n",
    "        # Normalize confusion matrix\n",
    "        conf_mat_norm = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(conf_mat_norm, annot=False, cmap='Blues', fmt='.2f', \n",
    "                    xticklabels=self.class_names if self.class_names else range(self.num_classes),\n",
    "                    yticklabels=self.class_names if self.class_names else range(self.num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_per_class_metrics(self, model_name, results=None, figsize=(15, 6)):\n",
    "        \"\"\"\n",
    "        Plot per-class precision, recall and F1\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model\n",
    "        results: dict, results from evaluate_classification_performance\n",
    "        figsize: tuple, figure size\n",
    "        \"\"\"\n",
    "        if results is None:\n",
    "            raise ValueError(\"Results dictionary must be provided\")\n",
    "            \n",
    "        if model_name not in results:\n",
    "            raise ValueError(f\"No results found for model {model_name}\")\n",
    "            \n",
    "        precision = results[model_name]['per_class_precision']\n",
    "        recall = results[model_name]['per_class_recall']\n",
    "        f1 = results[model_name]['per_class_f1']\n",
    "        \n",
    "        # Create dataframe for plotting\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Class': self.class_names if self.class_names else range(self.num_classes),\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "        \n",
    "        # Melt the dataframe for easier plotting\n",
    "        melted_df = pd.melt(metrics_df, id_vars=['Class'], var_name='Metric', value_name='Score')\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.barplot(x='Class', y='Score', hue='Metric', data=melted_df)\n",
    "        plt.title(f'Per-Class Performance Metrics - {model_name}')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_robustness_curves(self, robustness_results, corruption_types=None, figsize=(15, 6)):\n",
    "        \"\"\"\n",
    "        Plot robustness curves across corruption types and severities\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        robustness_results: dict, results from evaluate_robustness_metrics\n",
    "        corruption_types: list, corruption types to plot (None for all)\n",
    "        figsize: tuple, figure size\n",
    "        \"\"\"\n",
    "        if corruption_types is None:\n",
    "            # Extract all corruption types from first model\n",
    "            first_model = list(robustness_results.keys())[0]\n",
    "            corruption_types = set()\n",
    "            for key in robustness_results[first_model]['corruption_results'].keys():\n",
    "                if isinstance(key, tuple):\n",
    "                    corruption_types.add(key[0])\n",
    "            corruption_types = list(corruption_types)\n",
    "        \n",
    "        # Create a plot for each corruption type\n",
    "        for corruption in corruption_types:\n",
    "            plt.figure(figsize=figsize)\n",
    "            \n",
    "            for model_name, results in robustness_results.items():\n",
    "                severities = []\n",
    "                accuracies = []\n",
    "                \n",
    "                for key, val in results['corruption_results'].items():\n",
    "                    if isinstance(key, tuple) and key[0] == corruption:\n",
    "                        severity = key[1]\n",
    "                        severities.append(severity)\n",
    "                        accuracies.append(val['accuracy'])\n",
    "                \n",
    "                # Sort by severity\n",
    "                sorted_indices = np.argsort(severities)\n",
    "                severities = [severities[i] for i in sorted_indices]\n",
    "                accuracies = [accuracies[i] for i in sorted_indices]\n",
    "                \n",
    "                # Plot\n",
    "                plt.plot(severities, accuracies, marker='o', label=model_name)\n",
    "                \n",
    "                # Add clean performance as severity 0\n",
    "                plt.plot([0], [results['clean_accuracy']], marker='x', color='black')\n",
    "                \n",
    "            plt.xlabel('Corruption Severity')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Model Robustness Under {corruption.capitalize()} Corruption')\n",
    "            plt.legend()\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    def plot_efficiency_comparison(self, efficiency_results, metric='inference_time_ms', figsize=(10, 6)):\n",
    "        \"\"\"\n",
    "        Plot efficiency comparison between models\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        efficiency_results: dict, results from benchmark_efficiency\n",
    "        metric: str, which efficiency metric to plot\n",
    "        figsize: tuple, figure size\n",
    "        \"\"\"\n",
    "        model_names = list(efficiency_results.keys())\n",
    "        metric_values = [efficiency_results[name][metric] for name in model_names]\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        bars = plt.bar(model_names, metric_values)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}',\n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "        plt.ylabel(metric.replace('_', ' ').title())\n",
    "        plt.title(f'Model Efficiency Comparison - {metric.replace(\"_\", \" \").title()}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_ablation_results(self, ablation_results, figsize=(12, 6)):\n",
    "        \"\"\"\n",
    "        Plot results of ablation study\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        ablation_results: dict, results from ablation_study\n",
    "        figsize: tuple, figure size\n",
    "        \"\"\"\n",
    "        components = list(ablation_results.keys())\n",
    "        values = list(ablation_results.values())\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        bars = plt.bar(components, values)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.4f}',\n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Model Performance with Component Ablations')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylim(0, max(values) * 1.1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_transferability_heatmap(self, transferability_results, figsize=(10, 8)):\n",
    "        \"\"\"\n",
    "        Plot heatmap of attack transferability\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        transferability_results: dict, results from attack_transferability_analysis\n",
    "        figsize: tuple, figure size\n",
    "        \"\"\"\n",
    "        source_models = list(transferability_results.keys())\n",
    "        target_models = set()\n",
    "        for source in source_models:\n",
    "            target_models.update(transferability_results[source].keys())\n",
    "        target_models = list(target_models)\n",
    "        \n",
    "        # Create transfer success rate matrix\n",
    "        transfer_matrix = np.zeros((len(source_models), len(target_models)))\n",
    "        \n",
    "        for i, source in enumerate(source_models):\n",
    "            for j, target in enumerate(target_models):\n",
    "                if target in transferability_results[source]:\n",
    "                    transfer_matrix[i, j] = transferability_results[source][target]['transfer_success_rate']\n",
    "                else:\n",
    "                    transfer_matrix[i, j] = np.nan  # Self-transfer\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        mask = np.isnan(transfer_matrix)\n",
    "        sns.heatmap(transfer_matrix, annot=True, cmap='YlOrRd', fmt='.2f', \n",
    "                    xticklabels=target_models, yticklabels=source_models,\n",
    "                    mask=mask)\n",
    "        plt.xlabel('Target Model')\n",
    "        plt.ylabel('Source Model')\n",
    "        plt.title('Attack Transferability Success Rate')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ExperimentalProtocol:\n",
    "    \"\"\"Comprehensive experimental protocol for point cloud model training and evaluation.\"\"\"\n",
    "    \n",
    "    def __init__(self, models, dataset_path, num_points=1024, num_classes=40, \n",
    "                 batch_size=32, device=None):\n",
    "        \"\"\"\n",
    "        Initialize the experimental protocol\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        models: dict, dictionary of models to evaluate {name: model_init_function}\n",
    "        dataset_path: str, path to the ModelNet40 dataset\n",
    "        num_points: int, number of points per point cloud\n",
    "        num_classes: int, number of classes\n",
    "        batch_size: int, batch size for training\n",
    "        device: torch.device, device to use for training\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.dataset_path = dataset_path\n",
    "        self.num_points = num_points\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize dataset\n",
    "        self.full_dataset = ModelNet40Dataset(\n",
    "            root_dir=dataset_path,\n",
    "            split='train',  # We'll split this manually later\n",
    "            num_points=num_points,\n",
    "            random_rotation=True\n",
    "        )\n",
    "        \n",
    "        # Initialize helper classes\n",
    "        self.training_manager = TrainingManager(device=self.device)\n",
    "        self.cross_validator = CrossValidator()\n",
    "        self.hyperparameter_optimizer = HyperparameterOptimizer()\n",
    "        self.benchmark_protocol = BenchmarkProtocol(device=self.device)\n",
    "\n",
    "    def prepare_data_splits(self, test_size=0.15, val_size=0.15, seed=42):\n",
    "        \"\"\"\n",
    "        Prepare data splits for training, validation, and testing\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_size: float, fraction of data for testing\n",
    "        val_size: float, fraction of data for validation\n",
    "        seed: int, random seed for reproducibility\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        train_dataset, val_dataset, test_dataset: Dataset objects\n",
    "        \"\"\"\n",
    "        # Set random seeds for reproducibility\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # Get all data indices and labels for stratification\n",
    "        all_labels = [self.full_dataset.labels[i] for i in range(len(self.full_dataset))]\n",
    "        \n",
    "        # Calculate split sizes\n",
    "        dataset_size = len(self.full_dataset)\n",
    "        test_count = int(dataset_size * test_size)\n",
    "        val_count = int(dataset_size * val_size)\n",
    "        train_count = dataset_size - test_count - val_count\n",
    "        \n",
    "        # Create stratified splits\n",
    "        train_idx, temp_idx = self.cross_validator.stratified_split(\n",
    "            all_labels, train_count / dataset_size, seed\n",
    "        )\n",
    "        \n",
    "        # Further split temporary indices into validation and test sets\n",
    "        val_proportion = val_count / (val_count + test_count)\n",
    "        val_idx, test_idx = self.cross_validator.stratified_split(\n",
    "            [all_labels[i] for i in temp_idx], val_proportion, seed\n",
    "        )\n",
    "        val_idx = [temp_idx[i] for i in val_idx]\n",
    "        test_idx = [temp_idx[i] for i in test_idx]\n",
    "        \n",
    "        # Create dataset subsets\n",
    "        train_dataset = Subset(self.full_dataset, train_idx)\n",
    "        val_dataset = Subset(self.full_dataset, val_idx)\n",
    "        test_dataset = Subset(self.full_dataset, test_idx)\n",
    "        \n",
    "        print(f\"Dataset split: Training={len(train_dataset)}, Validation={len(val_dataset)}, Test={len(test_dataset)}\")\n",
    "        \n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "    \n",
    "    def run_full_protocol(self, model_name, train_dataset, val_dataset, test_dataset, output_dir=\"results\"):\n",
    "        \"\"\"\n",
    "        Run the complete experimental protocol for a single model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model to evaluate\n",
    "        train_dataset, val_dataset, test_dataset: Dataset objects\n",
    "        output_dir: str, directory to save results\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, complete evaluation results\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        results = {}\n",
    "        \n",
    "        # 1. Hyperparameter optimization on validation set\n",
    "        print(f\"Starting hyperparameter optimization for {model_name}...\")\n",
    "        best_params = self.hyperparameter_optimizer.optimize_model_hyperparams(\n",
    "            model_name, self.models[model_name], train_dataset, val_dataset, \n",
    "            self.num_classes, self.device\n",
    "        )\n",
    "        results['best_hyperparams'] = best_params\n",
    "        \n",
    "        # 2. Initialize model with best hyperparameters\n",
    "        model_init_fn = self.models[model_name]\n",
    "        model = model_init_fn(num_classes=self.num_classes, **best_params)\n",
    "        model.to(self.device)\n",
    "        \n",
    "        # 3. Multi-phase training\n",
    "        print(f\"Starting multi-phase training for {model_name}...\")\n",
    "        \n",
    "        # Clean pre-training phase\n",
    "        print(\"Phase 1: Clean pre-training\")\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        model = self.training_manager.train_clean(\n",
    "            model, train_loader, val_loader, \n",
    "            epochs=50, \n",
    "            lr=0.001, \n",
    "            weight_decay=0.01\n",
    "        )\n",
    "        \n",
    "        # Save checkpoint after clean training\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{model_name}_clean_trained.pth\")\n",
    "        \n",
    "        # Basic adversarial training phase\n",
    "        print(\"Phase 2: Adversarial training\")\n",
    "        model = self.training_manager.train_adversarial(\n",
    "            model, train_loader, val_loader,\n",
    "            epochs=30,\n",
    "            lr=0.0005,\n",
    "            attack_type='pgd',\n",
    "            epsilon=0.03,\n",
    "            alpha=0.007,\n",
    "            steps=10\n",
    "        )\n",
    "        \n",
    "        # Save checkpoint after adversarial training\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{model_name}_adv_trained.pth\")\n",
    "        \n",
    "        # Environmental corruption training phase\n",
    "        print(\"Phase 3: Environmental corruption training\")\n",
    "        model = self.training_manager.train_corruptions(\n",
    "            model, train_dataset, val_dataset,\n",
    "            epochs=30,\n",
    "            lr=0.0003,\n",
    "            batch_size=16,\n",
    "            corruptions=['gaussian_noise', 'snow', 'fog'],\n",
    "            severities=[1, 3, 5]\n",
    "        )\n",
    "        \n",
    "        # Save checkpoint after corruption training\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{model_name}_corruption_trained.pth\")\n",
    "        \n",
    "        # Combined robustness fine-tuning\n",
    "        print(\"Phase 4: Combined robustness fine-tuning\")\n",
    "        model = self.training_manager.train_combined_robustness(\n",
    "            model, train_dataset, val_dataset,\n",
    "            epochs=20,\n",
    "            lr=0.0001,\n",
    "            batch_size=16,\n",
    "            adv_weight=0.5,\n",
    "            corruption_weight=0.5\n",
    "        )\n",
    "        \n",
    "        # Save final model\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{model_name}_final.pth\")\n",
    "        \n",
    "        # 4. Comprehensive evaluation\n",
    "        print(f\"Evaluating final model for {model_name}...\")\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        evaluator = EvaluationFramework({model_name: model}, device=self.device, num_classes=self.num_classes)\n",
    "        \n",
    "        # Basic classification performance\n",
    "        class_results = evaluator.evaluate_classification_performance(test_loader)\n",
    "        results['classification_performance'] = class_results\n",
    "        \n",
    "        # Adversarial robustness\n",
    "        attacker = PointCloudAttacker(model, self.device)\n",
    "        adv_results = {}\n",
    "        \n",
    "        for attack_type in ['fgsm', 'pgd']:\n",
    "            for strength in [0.01, 0.03, 0.05]:\n",
    "                adv_acc = self._evaluate_adversarial_robustness(\n",
    "                    model, test_loader, attacker, attack_type, strength\n",
    "                )\n",
    "                adv_results[f\"{attack_type}_{strength}\"] = adv_acc\n",
    "        \n",
    "        results['adversarial_robustness'] = adv_results\n",
    "        \n",
    "        # Corruption robustness\n",
    "        corruption_results = {}\n",
    "        for corruption in ['gaussian_noise', 'fog', 'snow']:\n",
    "            for severity in [1, 3, 5]:\n",
    "                corrupted_dataset = get_corrupted_dataset(\n",
    "                    test_dataset, corruption, severity\n",
    "                )\n",
    "                corrupted_loader = DataLoader(\n",
    "                    corrupted_dataset, batch_size=self.batch_size, shuffle=False\n",
    "                )\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    for points, labels in corrupted_loader:\n",
    "                        points, labels = points.to(self.device), labels.to(self.device)\n",
    "                        outputs = model(points)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        correct += predicted.eq(labels).sum().item()\n",
    "                        total += labels.size(0)\n",
    "                \n",
    "                corruption_results[f\"{corruption}_{severity}\"] = correct / total\n",
    "        \n",
    "        results['corruption_robustness'] = corruption_results\n",
    "        \n",
    "        # Save results\n",
    "        np.save(f\"{output_dir}/{model_name}_results.npy\", results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_adversarial_robustness(self, model, dataloader, attacker, attack_type, strength):\n",
    "        \"\"\"Helper method to evaluate adversarial robustness\"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for points, labels in dataloader:\n",
    "            points, labels = points.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Generate adversarial examples\n",
    "            if attack_type == 'fgsm':\n",
    "                adv_points = attacker.fgsm_attack(points, labels, epsilon=strength)\n",
    "            elif attack_type == 'pgd':\n",
    "                adv_points = attacker.pgd_attack(points, labels, epsilon=strength, alpha=strength/4)\n",
    "                \n",
    "            # Evaluate\n",
    "            with torch.no_grad():\n",
    "                outputs = model(adv_points)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        return correct / total\n",
    "        \n",
    "    def run_cross_validation(self, model_name, n_folds=5, seed=42):\n",
    "        \"\"\"\n",
    "        Run the full k-fold cross-validation procedure\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model to evaluate\n",
    "        n_folds: int, number of folds for cross-validation\n",
    "        seed: int, random seed for reproducibility\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        cv_results: dict, cross-validation results\n",
    "        \"\"\"\n",
    "        # Get all data points and labels\n",
    "        all_data_idx = list(range(len(self.full_dataset)))\n",
    "        all_labels = [self.full_dataset.labels[i] for i in range(len(self.full_dataset))]\n",
    "        \n",
    "        # Initialize stratified k-fold\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        \n",
    "        fold_results = []\n",
    "        \n",
    "        for fold, (train_val_idx, test_idx) in enumerate(skf.split(all_data_idx, all_labels)):\n",
    "            print(f\"\\n--- Fold {fold+1}/{n_folds} ---\")\n",
    "            \n",
    "            # Split train_val into train and validation\n",
    "            train_idx, val_idx = self.cross_validator.stratified_split(\n",
    "                [all_labels[i] for i in train_val_idx], 0.8, seed + fold\n",
    "            )\n",
    "            train_idx = [train_val_idx[i] for i in train_idx]\n",
    "            val_idx = [train_val_idx[i] for i in val_idx]\n",
    "            \n",
    "            # Create dataset subsets\n",
    "            train_dataset = Subset(self.full_dataset, train_idx)\n",
    "            val_dataset = Subset(self.full_dataset, val_idx)\n",
    "            test_dataset = Subset(self.full_dataset, test_idx)\n",
    "            \n",
    "            # Run the full protocol\n",
    "            output_dir = f\"results/cv_fold_{fold+1}\"\n",
    "            fold_result = self.run_full_protocol(\n",
    "                model_name, train_dataset, val_dataset, test_dataset, output_dir\n",
    "            )\n",
    "            \n",
    "            fold_results.append(fold_result)\n",
    "        \n",
    "        # Aggregate cross-validation results\n",
    "        cv_results = self._aggregate_cv_results(fold_results)\n",
    "        \n",
    "        return cv_results\n",
    "    \n",
    "    def _aggregate_cv_results(self, fold_results):\n",
    "        \"\"\"Helper method to aggregate cross-validation results\"\"\"\n",
    "        # Extract metrics across folds\n",
    "        classification_metrics = {\n",
    "            'top1_accuracy': [],\n",
    "            'avg_precision': [],\n",
    "            'avg_recall': [],\n",
    "            'avg_f1': []\n",
    "        }\n",
    "        \n",
    "        for result in fold_results:\n",
    "            model_name = list(result['classification_performance'].keys())[0]\n",
    "            metrics = result['classification_performance'][model_name]\n",
    "            \n",
    "            classification_metrics['top1_accuracy'].append(metrics['top1_accuracy'])\n",
    "            classification_metrics['avg_precision'].append(metrics['avg_precision'])\n",
    "            classification_metrics['avg_recall'].append(metrics['avg_recall'])\n",
    "            classification_metrics['avg_f1'].append(metrics['avg_f1'])\n",
    "        \n",
    "        # Calculate mean and standard deviation\n",
    "        aggregated = {}\n",
    "        for metric, values in classification_metrics.items():\n",
    "            aggregated[f'mean_{metric}'] = np.mean(values)\n",
    "            aggregated[f'std_{metric}'] = np.std(values)\n",
    "        \n",
    "        return aggregated\n",
    "    \n",
    "    def benchmark_against_baselines(self, model_name, baselines, train_dataset, val_dataset, test_dataset):\n",
    "        \"\"\"\n",
    "        Benchmark the model against baseline methods\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model to evaluate\n",
    "        baselines: dict, {name: model_init_function} for baseline models\n",
    "        train_dataset, val_dataset, test_dataset: Dataset objects\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        benchmark_results: dict, comparative results\n",
    "        \"\"\"\n",
    "        # Add target model to the baselines\n",
    "        all_models = {**{model_name: self.models[model_name]}, **baselines}\n",
    "        model_performances = {}\n",
    "        \n",
    "        # Train and evaluate each model\n",
    "        for name, model_fn in all_models.items():\n",
    "            print(f\"\\nEvaluating model: {name}\")\n",
    "            \n",
    "            # Initialize model\n",
    "            model = model_fn(num_classes=self.num_classes)\n",
    "    \n",
    "class ExperimentalProtocol:\n",
    "    \"\"\"Comprehensive experimental protocol for point cloud model training and evaluation.\"\"\"\n",
    "    \n",
    "    def __init__(self, models, dataset_path, num_points=1024, num_classes=40, \n",
    "                 batch_size=32, device=None):\n",
    "        \"\"\"\n",
    "        Initialize the experimental protocol\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        models: dict, dictionary of models to evaluate {name: model_init_function}\n",
    "        dataset_path: str, path to the ModelNet40 dataset\n",
    "        num_points: int, number of points per point cloud\n",
    "        num_classes: int, number of classes\n",
    "        batch_size: int, batch size for training\n",
    "        device: torch.device, device to use for training\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.dataset_path = dataset_path\n",
    "        self.num_points = num_points\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize dataset\n",
    "        self.full_dataset = ModelNet40Dataset(\n",
    "            root_dir=dataset_path,\n",
    "            split='train',  # We'll split this manually later\n",
    "            num_points=num_points,\n",
    "            random_rotation=True\n",
    "        )\n",
    "        \n",
    "        # Initialize helper classes\n",
    "        self.training_manager = TrainingManager(device=self.device)\n",
    "        self.cross_validator = CrossValidator()\n",
    "        self.hyperparameter_optimizer = HyperparameterOptimizer()\n",
    "        self.benchmark_protocol = BenchmarkProtocol(device=self.device)\n",
    "\n",
    "    def prepare_data_splits(self, test_size=0.15, val_size=0.15, seed=42):\n",
    "        \"\"\"\n",
    "        Prepare data splits for training, validation, and testing\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_size: float, fraction of data for testing\n",
    "        val_size: float, fraction of data for validation\n",
    "        seed: int, random seed for reproducibility\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        train_dataset, val_dataset, test_dataset: Dataset objects\n",
    "        \"\"\"\n",
    "        # Set random seeds for reproducibility\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # Get all data indices and labels for stratification\n",
    "        all_labels = [self.full_dataset.labels[i] for i in range(len(self.full_dataset))]\n",
    "        \n",
    "        # Calculate split sizes\n",
    "        dataset_size = len(self.full_dataset)\n",
    "        test_count = int(dataset_size * test_size)\n",
    "        val_count = int(dataset_size * val_size)\n",
    "        train_count = dataset_size - test_count - val_count\n",
    "        \n",
    "        # Create stratified splits\n",
    "        train_idx, temp_idx = self.cross_validator.stratified_split(\n",
    "            all_labels, train_count / dataset_size, seed\n",
    "        )\n",
    "        \n",
    "        # Further split temporary indices into validation and test sets\n",
    "        val_proportion = val_count / (val_count + test_count)\n",
    "        val_idx, test_idx = self.cross_validator.stratified_split(\n",
    "            [all_labels[i] for i in temp_idx], val_proportion, seed\n",
    "        )\n",
    "        val_idx = [temp_idx[i] for i in val_idx]\n",
    "        test_idx = [temp_idx[i] for i in test_idx]\n",
    "        \n",
    "        # Create dataset subsets\n",
    "        train_dataset = Subset(self.full_dataset, train_idx)\n",
    "        val_dataset = Subset(self.full_dataset, val_idx)\n",
    "        test_dataset = Subset(self.full_dataset, test_idx)\n",
    "        \n",
    "        print(f\"Dataset split: Training={len(train_dataset)}, Validation={len(val_dataset)}, Test={len(test_dataset)}\")\n",
    "        \n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "    \n",
    "    def run_full_protocol(self, model_name, train_dataset, val_dataset, test_dataset, output_dir=\"results\"):\n",
    "        \"\"\"\n",
    "        Run the complete experimental protocol for a single model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model to evaluate\n",
    "        train_dataset, val_dataset, test_dataset: Dataset objects\n",
    "        output_dir: str, directory to save results\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, complete evaluation results\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        results = {}\n",
    "        \n",
    "        # 1. Hyperparameter optimization on validation set\n",
    "        print(f\"Starting hyperparameter optimization for {model_name}...\")\n",
    "        best_params = self.hyperparameter_optimizer.optimize_model_hyperparams(\n",
    "            model_name, self.models[model_name], train_dataset, val_dataset, \n",
    "            self.num_classes, self.device\n",
    "        )\n",
    "        results['best_hyperparams'] = best_params\n",
    "        \n",
    "        # 2. Initialize model with best hyperparameters\n",
    "        model_init_fn = self.models[model_name]\n",
    "        model = model_init_fn(num_classes=self.num_classes, **best_params)\n",
    "        model.to(self.device)\n",
    "        \n",
    "        # 3. Multi-phase training\n",
    "        print(f\"Starting multi-phase training for {model_name}...\")\n",
    "        \n",
    "        # Clean pre-training phase\n",
    "        print(\"Phase 1: Clean pre-training\")\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        model = self.training_manager.train_clean(\n",
    "            model, train_loader, val_loader, \n",
    "            epochs=50, \n",
    "            lr=0.001, \n",
    "            weight_decay=0.01\n",
    "        )\n",
    "        \n",
    "        # Save checkpoint after clean training\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{model_name}_clean_trained.pth\")\n",
    "        \n",
    "        # Basic adversarial training phase\n",
    "        print(\"Phase 2: Adversarial training\")\n",
    "        model = self.training_manager.train_adversarial(\n",
    "            model, train_loader, val_loader,\n",
    "            epochs=30,\n",
    "            lr=0.0005,\n",
    "            attack_type='pgd',\n",
    "            epsilon=0.03,\n",
    "            alpha=0.007,\n",
    "            steps=10\n",
    "        )\n",
    "        \n",
    "        # Save checkpoint after adversarial training\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{model_name}_adv_trained.pth\")\n",
    "        \n",
    "        # Environmental corruption training phase\n",
    "        print(\"Phase 3: Environmental corruption training\")\n",
    "        model = self.training_manager.train_corruptions(\n",
    "            model, train_dataset, val_dataset,\n",
    "            epochs=30,\n",
    "            lr=0.0003,\n",
    "            batch_size=16,\n",
    "            corruptions=['gaussian_noise', 'snow', 'fog'],\n",
    "            severities=[1, 3, 5]\n",
    "        )\n",
    "        \n",
    "        # Save checkpoint after corruption training\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{model_name}_corruption_trained.pth\")\n",
    "        \n",
    "        # Combined robustness fine-tuning\n",
    "        print(\"Phase 4: Combined robustness fine-tuning\")\n",
    "        model = self.training_manager.train_combined_robustness(\n",
    "            model, train_dataset, val_dataset,\n",
    "            epochs=20,\n",
    "            lr=0.0001,\n",
    "            batch_size=16,\n",
    "            adv_weight=0.5,\n",
    "            corruption_weight=0.5\n",
    "        )\n",
    "        \n",
    "        # Save final model\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{model_name}_final.pth\")\n",
    "        \n",
    "        # 4. Comprehensive evaluation\n",
    "        print(f\"Evaluating final model for {model_name}...\")\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        evaluator = EvaluationFramework({model_name: model}, device=self.device, num_classes=self.num_classes)\n",
    "        \n",
    "        # Basic classification performance\n",
    "        class_results = evaluator.evaluate_classification_performance(test_loader)\n",
    "        results['classification_performance'] = class_results\n",
    "        \n",
    "        # Adversarial robustness\n",
    "        attacker = PointCloudAttacker(model, self.device)\n",
    "        adv_results = {}\n",
    "        \n",
    "        for attack_type in ['fgsm', 'pgd']:\n",
    "            for strength in [0.01, 0.03, 0.05]:\n",
    "                adv_acc = self._evaluate_adversarial_robustness(\n",
    "                    model, test_loader, attacker, attack_type, strength\n",
    "                )\n",
    "                adv_results[f\"{attack_type}_{strength}\"] = adv_acc\n",
    "        \n",
    "        results['adversarial_robustness'] = adv_results\n",
    "        \n",
    "        # Corruption robustness\n",
    "        corruption_results = {}\n",
    "        for corruption in ['gaussian_noise', 'fog', 'snow']:\n",
    "            for severity in [1, 3, 5]:\n",
    "                corrupted_dataset = get_corrupted_dataset(\n",
    "                    test_dataset, corruption, severity\n",
    "                )\n",
    "                corrupted_loader = DataLoader(\n",
    "                    corrupted_dataset, batch_size=self.batch_size, shuffle=False\n",
    "                )\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    for points, labels in corrupted_loader:\n",
    "                        points, labels = points.to(self.device), labels.to(self.device)\n",
    "                        outputs = model(points)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        correct += predicted.eq(labels).sum().item()\n",
    "                        total += labels.size(0)\n",
    "                \n",
    "                corruption_results[f\"{corruption}_{severity}\"] = correct / total\n",
    "        \n",
    "        results['corruption_robustness'] = corruption_results\n",
    "        \n",
    "        # Save results\n",
    "        np.save(f\"{output_dir}/{model_name}_results.npy\", results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_adversarial_robustness(self, model, dataloader, attacker, attack_type, strength):\n",
    "        \"\"\"Helper method to evaluate adversarial robustness\"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for points, labels in dataloader:\n",
    "            points, labels = points.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Generate adversarial examples\n",
    "            if attack_type == 'fgsm':\n",
    "                adv_points = attacker.fgsm_attack(points, labels, epsilon=strength)\n",
    "            elif attack_type == 'pgd':\n",
    "                adv_points = attacker.pgd_attack(points, labels, epsilon=strength, alpha=strength/4)\n",
    "                \n",
    "            # Evaluate\n",
    "            with torch.no_grad():\n",
    "                outputs = model(adv_points)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        return correct / total\n",
    "        \n",
    "    def run_cross_validation(self, model_name, n_folds=5, seed=42):\n",
    "        \"\"\"\n",
    "        Run the full k-fold cross-validation procedure\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model to evaluate\n",
    "        n_folds: int, number of folds for cross-validation\n",
    "        seed: int, random seed for reproducibility\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        cv_results: dict, cross-validation results\n",
    "        \"\"\"\n",
    "        # Get all data points and labels\n",
    "        all_data_idx = list(range(len(self.full_dataset)))\n",
    "        all_labels = [self.full_dataset.labels[i] for i in range(len(self.full_dataset))]\n",
    "        \n",
    "        # Initialize stratified k-fold\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        \n",
    "        fold_results = []\n",
    "        \n",
    "        for fold, (train_val_idx, test_idx) in enumerate(skf.split(all_data_idx, all_labels)):\n",
    "            print(f\"\\n--- Fold {fold+1}/{n_folds} ---\")\n",
    "            \n",
    "            # Split train_val into train and validation\n",
    "            train_idx, val_idx = self.cross_validator.stratified_split(\n",
    "                [all_labels[i] for i in train_val_idx], 0.8, seed + fold\n",
    "            )\n",
    "            train_idx = [train_val_idx[i] for i in train_idx]\n",
    "            val_idx = [train_val_idx[i] for i in val_idx]\n",
    "            \n",
    "            # Create dataset subsets\n",
    "            train_dataset = Subset(self.full_dataset, train_idx)\n",
    "            val_dataset = Subset(self.full_dataset, val_idx)\n",
    "            test_dataset = Subset(self.full_dataset, test_idx)\n",
    "            \n",
    "            # Run the full protocol\n",
    "            output_dir = f\"results/cv_fold_{fold+1}\"\n",
    "            fold_result = self.run_full_protocol(\n",
    "                model_name, train_dataset, val_dataset, test_dataset, output_dir\n",
    "            )\n",
    "            \n",
    "            fold_results.append(fold_result)\n",
    "        \n",
    "        # Aggregate cross-validation results\n",
    "        cv_results = self._aggregate_cv_results(fold_results)\n",
    "        \n",
    "        return cv_results\n",
    "    \n",
    "    def _aggregate_cv_results(self, fold_results):\n",
    "        \"\"\"Helper method to aggregate cross-validation results\"\"\"\n",
    "        # Extract metrics across folds\n",
    "        classification_metrics = {\n",
    "            'top1_accuracy': [],\n",
    "            'avg_precision': [],\n",
    "            'avg_recall': [],\n",
    "            'avg_f1': []\n",
    "        }\n",
    "        \n",
    "        for result in fold_results:\n",
    "            model_name = list(result['classification_performance'].keys())[0]\n",
    "            metrics = result['classification_performance'][model_name]\n",
    "            \n",
    "            classification_metrics['top1_accuracy'].append(metrics['top1_accuracy'])\n",
    "            classification_metrics['avg_precision'].append(metrics['avg_precision'])\n",
    "            classification_metrics['avg_recall'].append(metrics['avg_recall'])\n",
    "            classification_metrics['avg_f1'].append(metrics['avg_f1'])\n",
    "        \n",
    "        # Calculate mean and standard deviation\n",
    "        aggregated = {}\n",
    "        for metric, values in classification_metrics.items():\n",
    "            aggregated[f'mean_{metric}'] = np.mean(values)\n",
    "            aggregated[f'std_{metric}'] = np.std(values)\n",
    "        \n",
    "        return aggregated\n",
    "    \n",
    "    def benchmark_against_baselines(self, model_name, baselines, train_dataset, val_dataset, test_dataset):\n",
    "        \"\"\"\n",
    "        Benchmark the model against baseline methods\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model to evaluate\n",
    "        baselines: dict, {name: model_init_function} for baseline models\n",
    "        train_dataset, val_dataset, test_dataset: Dataset objects\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        benchmark_results: dict, comparative results\n",
    "        \"\"\"\n",
    "        # Add target model to the baselines\n",
    "        all_models = {**{model_name: self.models[model_name]}, **baselines}\n",
    "        model_performances = {}\n",
    "        \n",
    "        # Train and evaluate each model\n",
    "        for name, model_fn in all_models.items():\n",
    "            print(f\"\\nEvaluating model: {name}\")\n",
    "            \n",
    "            # Initialize model\n",
    "            model = model_fn(num_classes=self.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingManager:\n",
    "    \"\"\"Class for managing model training with various techniques\"\"\"\n",
    "    \n",
    "    def __init__(self, device=None):\n",
    "        \"\"\"\n",
    "        Initialize the training manager\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        device: torch.device, device to use for training\n",
    "        \"\"\"\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def train_clean(self, model, train_loader, val_loader, epochs=100, lr=0.001, weight_decay=0.0):\n",
    "        \"\"\"\n",
    "        Train a model on clean data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model: torch.nn.Module, model to train\n",
    "        train_loader: DataLoader, training data\n",
    "        val_loader: DataLoader, validation data\n",
    "        epochs: int, number of epochs to train\n",
    "        lr: float, learning rate\n",
    "        weight_decay: float, weight decay for regularization\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        model: torch.nn.Module, trained model\n",
    "        \"\"\"\n",
    "        model.to(self.device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for points, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False):\n",
    "                points, labels = points.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            train_acc = correct / total\n",
    "            train_loss = train_loss / len(train_loader)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for points, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False):\n",
    "                    points, labels = points.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(points)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            val_acc = correct / total\n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            \n",
    "            # Learning rate scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}: train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(best_model_state)\n",
    "        return model\n",
    "        \n",
    "    def train_adversarial(self, model, train_loader, val_loader, epochs=30, lr=0.0005, \n",
    "                          attack_type='pgd', epsilon=0.03, alpha=0.007, steps=10):\n",
    "        \"\"\"\n",
    "        Train a model with adversarial examples\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model: torch.nn.Module, model to train\n",
    "        train_loader: DataLoader, training data\n",
    "        val_loader: DataLoader, validation data\n",
    "        epochs: int, number of epochs to train\n",
    "        lr: float, learning rate\n",
    "        attack_type: str, type of attack ('pgd' or 'fgsm')\n",
    "        epsilon: float, attack strength\n",
    "        alpha: float, step size for PGD attack\n",
    "        steps: int, number of steps for PGD attack\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        model: torch.nn.Module, trained model\n",
    "        \"\"\"\n",
    "        model.to(self.device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Create attacker\n",
    "        attacker = PointCloudAttacker(model, self.device)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            clean_correct = 0\n",
    "            adv_correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for points, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False):\n",
    "                points, labels = points.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Generate adversarial examples\n",
    "                if attack_type == 'pgd':\n",
    "                    adv_points = attacker.pgd_attack(points, labels, epsilon=epsilon, alpha=alpha, num_iter=steps)\n",
    "                else:  # Default to FGSM\n",
    "                    adv_points = attacker.fgsm_attack(points, labels, epsilon=epsilon)\n",
    "                \n",
    "                # Train on mixture of clean and adversarial examples\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass on clean points\n",
    "                outputs_clean = model(points)\n",
    "                loss_clean = criterion(outputs_clean, labels)\n",
    "                \n",
    "                # Forward pass on adversarial points\n",
    "                outputs_adv = model(adv_points)\n",
    "                loss_adv = criterion(outputs_adv, labels)\n",
    "                \n",
    "                # Combined loss\n",
    "                loss = 0.5 * loss_clean + 0.5 * loss_adv\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                \n",
    "                # Clean accuracy\n",
    "                _, predicted = outputs_clean.max(1)\n",
    "                clean_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Adversarial accuracy\n",
    "                _, predicted = outputs_adv.max(1)\n",
    "                adv_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                total += labels.size(0)\n",
    "            \n",
    "            train_clean_acc = clean_correct / total\n",
    "            train_adv_acc = adv_correct / total\n",
    "            train_loss = train_loss / len(train_loader)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_clean_acc, val_adv_acc = self._evaluate_adversarial(model, val_loader, attacker, attack_type, epsilon, alpha, steps)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}: train_loss={train_loss:.4f}, train_clean_acc={train_clean_acc:.4f}, train_adv_acc={train_adv_acc:.4f}, \"\n",
    "                  f\"val_clean_acc={val_clean_acc:.4f}, val_adv_acc={val_adv_acc:.4f}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _evaluate_adversarial(self, model, dataloader, attacker, attack_type, epsilon, alpha=None, steps=None):\n",
    "        \"\"\"Helper method to evaluate adversarial robustness\"\"\"\n",
    "        model.eval()\n",
    "        clean_correct = 0\n",
    "        adv_correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for points, labels in dataloader:\n",
    "                points, labels = points.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Clean accuracy\n",
    "                outputs = model(points)\n",
    "                _, predicted = outputs.max(1)\n",
    "                clean_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                total += labels.size(0)\n",
    "        \n",
    "        # Adversarial accuracy\n",
    "        for points, labels in dataloader:\n",
    "            points, labels = points.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Generate adversarial examples\n",
    "            if attack_type == 'pgd':\n",
    "                adv_points = attacker.pgd_attack(points, labels, epsilon=epsilon, alpha=alpha, num_iter=steps)\n",
    "            else:  # Default to FGSM\n",
    "                adv_points = attacker.fgsm_attack(points, labels, epsilon=epsilon)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(adv_points)\n",
    "                _, predicted = outputs.max(1)\n",
    "                adv_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        return clean_correct / total, adv_correct / total\n",
    "    \n",
    "    def train_corruptions(self, model, train_dataset, val_dataset, epochs=30, lr=0.0003, \n",
    "                          batch_size=16, corruptions=None, severities=None):\n",
    "        \"\"\"\n",
    "        Train a model with environmental corruptions\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model: torch.nn.Module, model to train\n",
    "        train_dataset: Dataset, training dataset\n",
    "        val_dataset: Dataset, validation dataset\n",
    "        epochs: int, number of epochs to train\n",
    "        lr: float, learning rate\n",
    "        batch_size: int, batch size\n",
    "        corruptions: list, types of corruptions to use\n",
    "        severities: list, severity levels to use\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        model: torch.nn.Module, trained model\n",
    "        \"\"\"\n",
    "        if corruptions is None:\n",
    "            corruptions = ['gaussian_noise', 'snow', 'fog']\n",
    "        \n",
    "        if severities is None:\n",
    "            severities = [1, 3, 5]\n",
    "        \n",
    "        model.to(self.device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Create clean data loader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            clean_correct = 0\n",
    "            corrupt_correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # Random corruption type and severity for this epoch\n",
    "            corruption = random.choice(corruptions)\n",
    "            severity = random.choice(severities)\n",
    "            \n",
    "            # Create corrupted dataset\n",
    "            corrupt_train_dataset = get_corrupted_dataset(train_dataset, corruption, severity)\n",
    "            corrupt_train_loader = DataLoader(corrupt_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            # Train on both clean and corrupted data\n",
    "            for (clean_points, labels), (corrupt_points, _) in zip(train_loader, corrupt_train_loader):\n",
    "                clean_points, corrupt_points, labels = clean_points.to(self.device), corrupt_points.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass on clean points\n",
    "                outputs_clean = model(clean_points)\n",
    "                loss_clean = criterion(outputs_clean, labels)\n",
    "                \n",
    "                # Forward pass on corrupted points\n",
    "                outputs_corrupt = model(corrupt_points)\n",
    "                loss_corrupt = criterion(outputs_corrupt, labels)\n",
    "                \n",
    "                # Combined loss\n",
    "                loss = 0.5 * loss_clean + 0.5 * loss_corrupt\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Clean accuracy\n",
    "                _, predicted = outputs_clean.max(1)\n",
    "                clean_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Corrupted accuracy\n",
    "                _, predicted = outputs_corrupt.max(1)\n",
    "                corrupt_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                total += labels.size(0)\n",
    "            \n",
    "            train_clean_acc = clean_correct / total\n",
    "            train_corrupt_acc = corrupt_correct / total\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # Random corruption for validation\n",
    "            val_corruption = random.choice(corruptions)\n",
    "            val_severity = random.choice(severities)\n",
    "            corrupt_val_dataset = get_corrupted_dataset(val_dataset, val_corruption, val_severity)\n",
    "            corrupt_val_loader = DataLoader(corrupt_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for corrupt_points, labels in corrupt_val_loader:\n",
    "                    corrupt_points, labels = corrupt_points.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(corrupt_points)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            val_acc = correct / total\n",
    "            val_loss = val_loss / len(corrupt_val_loader)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}: train_loss={avg_loss:.4f}, train_clean_acc={train_clean_acc:.4f}, \"\n",
    "                  f\"train_corrupt_acc={train_corrupt_acc:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(best_model_state)\n",
    "        return model\n",
    "    \n",
    "    def train_combined_robustness(self, model, train_dataset, val_dataset, epochs=20, lr=0.0001,\n",
    "                                 batch_size=16, adv_weight=0.5, corruption_weight=0.5):\n",
    "        \"\"\"\n",
    "        Train a model with combined adversarial and corruption robustness\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model: torch.nn.Module, model to train\n",
    "        train_dataset: Dataset, training dataset\n",
    "        val_dataset: Dataset, validation dataset\n",
    "        epochs: int, number of epochs to train\n",
    "        lr: float, learning rate\n",
    "        batch_size: int, batch size\n",
    "        adv_weight: float, weight for adversarial loss\n",
    "        corruption_weight: float, weight for corruption loss\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        model: torch.nn.Module, trained model\n",
    "        \"\"\"\n",
    "        model.to(self.device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Create attacker\n",
    "        attacker = PointCloudAttacker(model, self.device)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Define corruptions\n",
    "        corruptions = ['gaussian_noise', 'snow', 'fog']\n",
    "        severities = [1, 3, 5]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            clean_correct = 0\n",
    "            adv_correct = 0\n",
    "            corrupt_correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # Random corruption for this epoch\n",
    "            corruption = random.choice(corruptions)\n",
    "            severity = random.choice(severities)\n",
    "            corrupt_train_dataset = get_corrupted_dataset(train_dataset, corruption, severity)\n",
    "            corrupt_train_loader = DataLoader(corrupt_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            for i, ((clean_points, labels), (corrupt_points, _)) in enumerate(zip(train_loader, corrupt_train_loader)):\n",
    "                clean_points = clean_points.to(self.device)\n",
    "                corrupt_points = corrupt_points.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Clean forward pass\n",
    "                outputs_clean = model(clean_points)\n",
    "                loss_clean = criterion(outputs_clean, labels)\n",
    "                \n",
    "                # Adversarial examples\n",
    "                adv_points = attacker.pgd_attack(clean_points, labels, epsilon=0.03, alpha=0.007, num_iter=10)\n",
    "                outputs_adv = model(adv_points)\n",
    "                loss_adv = criterion(outputs_adv, labels)\n",
    "                \n",
    "                # Corrupted examples\n",
    "                outputs_corrupt = model(corrupt_points)\n",
    "                loss_corrupt = criterion(outputs_corrupt, labels)\n",
    "                \n",
    "                # Combined loss\n",
    "                clean_weight = 1.0 - adv_weight - corruption_weight\n",
    "                loss = clean_weight * loss_clean + adv_weight * loss_adv + corruption_weight * loss_corrupt\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Track accuracy\n",
    "                _, predicted = outputs_clean.max(1)\n",
    "                clean_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                _, predicted = outputs_adv.max(1)\n",
    "                adv_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                _, predicted = outputs_corrupt.max(1)\n",
    "                corrupt_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Print progress every 50 batches\n",
    "                if (i+1) % 50 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{epochs}, Batch {i+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "            \n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            clean_acc = clean_correct / total\n",
    "            adv_acc = adv_correct / total\n",
    "            corrupt_acc = corrupt_correct / total\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}: loss={avg_loss:.4f}, clean_acc={clean_acc:.4f}, \"\n",
    "                  f\"adv_acc={adv_acc:.4f}, corrupt_acc={corrupt_acc:.4f}\")\n",
    "            \n",
    "            # Validation\n",
    "            val_clean_acc, val_adv_acc, val_corrupt_acc = self._evaluate_combined_robustness(\n",
    "                model, val_dataset, attacker, corruption, severity, batch_size)\n",
    "            \n",
    "            print(f\"Validation: clean_acc={val_clean_acc:.4f}, adv_acc={val_adv_acc:.4f}, corrupt_acc={val_corrupt_acc:.4f}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _evaluate_combined_robustness(self, model, dataset, attacker, corruption, severity, batch_size):\n",
    "        \"\"\"Helper method to evaluate combined robustness\"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Create data loaders\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Create corrupted dataset\n",
    "        corrupt_dataset = get_corrupted_dataset(dataset, corruption, severity)\n",
    "        corrupt_loader = DataLoader(corrupt_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Clean accuracy\n",
    "        clean_correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for points, labels in val_loader:\n",
    "                points, labels = points.to(self.device), labels.to(self.device)\n",
    "                outputs = model(points)\n",
    "                _, predicted = outputs.max(1)\n",
    "                clean_correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        clean_acc = clean_correct / total\n",
    "        \n",
    "        # Adversarial accuracy\n",
    "        adv_correct = 0\n",
    "        total = 0\n",
    "        for points, labels in val_loader:\n",
    "            points, labels = points.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Generate adversarial examples\n",
    "            adv_points = attacker.pgd_attack(points, labels, epsilon=0.03, alpha=0.007, num_iter=10)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(adv_points)\n",
    "                _, predicted = outputs.max(1)\n",
    "                adv_correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        adv_acc = adv_correct / total\n",
    "        \n",
    "        # Corruption accuracy\n",
    "        corrupt_correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for points, labels in corrupt_loader:\n",
    "                points, labels = points.to(self.device), labels.to(self.device)\n",
    "                outputs = model(points)\n",
    "                _, predicted = outputs.max(1)\n",
    "                corrupt_correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        corrupt_acc = corrupt_correct / total\n",
    "        \n",
    "        return clean_acc, adv_acc, corrupt_acc\n",
    "\n",
    "\n",
    "class CrossValidator:\n",
    "    \"\"\"Class for cross-validation procedures\"\"\"\n",
    "    \n",
    "    def stratified_split(self, labels, train_ratio, random_seed=None):\n",
    "        \"\"\"\n",
    "        Perform stratified split of data indices\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        labels: list, class labels for each sample\n",
    "        train_ratio: float, ratio of data for training\n",
    "        random_seed: int, random seed for reproducibility\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        train_indices, test_indices: lists of indices for training and testing\n",
    "        \"\"\"\n",
    "        if random_seed is not None:\n",
    "            np.random.seed(random_seed)\n",
    "        \n",
    "        # Get unique labels and their counts\n",
    "        unique_labels = np.unique(labels)\n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        # Split each class proportionally\n",
    "        for label in unique_labels:\n",
    "            indices = [i for i, l in enumerate(labels) if l == label]\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            # Calculate split point\n",
    "            split = int(len(indices) * train_ratio)\n",
    "            \n",
    "            # Add indices to respective sets\n",
    "            train_indices.extend(indices[:split])\n",
    "            test_indices.extend(indices[split:])\n",
    "        \n",
    "        return train_indices, test_indices\n",
    "\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    \"\"\"Class for hyperparameter optimization\"\"\"\n",
    "    \n",
    "    def optimize_model_hyperparams(self, model_name, model_init_fn, train_dataset, val_dataset, \n",
    "                                  num_classes=40, device=None):\n",
    "        \"\"\"\n",
    "        Optimize hyperparameters for a model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_name: str, name of the model\n",
    "        model_init_fn: function, model initialization function\n",
    "        train_dataset: Dataset, training dataset\n",
    "        val_dataset: Dataset, validation dataset\n",
    "        num_classes: int, number of classes\n",
    "        device: torch.device, device to use\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        best_params: dict, best hyperparameters\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        print(f\"Optimizing hyperparameters for {model_name}...\")\n",
    "        \n",
    "        # Define hyperparameter search space based on model\n",
    "        if model_name == \"pointnet++\":\n",
    "            param_grid = {\n",
    "                \"lr\": [0.001, 0.0005],\n",
    "                \"weight_decay\": [0.0, 0.001],\n",
    "                \"batch_size\": [16, 32]\n",
    "            }\n",
    "        elif model_name == \"dgcnn\":\n",
    "            param_grid = {\n",
    "                \"lr\": [0.001, 0.0005],\n",
    "                \"weight_decay\": [0.0, 0.001],\n",
    "                \"batch_size\": [16, 32],\n",
    "                \"k\": [20, 40]  # k-nearest neighbors\n",
    "            }\n",
    "        elif model_name == \"pointmlp\":\n",
    "            param_grid = {\n",
    "                \"lr\": [0.001, 0.0005],\n",
    "                \"weight_decay\": [0.0, 0.001],\n",
    "                \"batch_size\": [16, 32],\n",
    "                \"embed_dim\": [64, 128]\n",
    "            }\n",
    "        else:  # Default for custom attention model\n",
    "            param_grid = {\n",
    "                \"lr\": [0.001, 0.0005],\n",
    "                \"weight_decay\": [0.0, 0.001],\n",
    "                \"batch_size\": [16, 32],\n",
    "                \"embed_dim\": [64, 128],\n",
    "                \"heads\": [4, 8]\n",
    "            }\n",
    "        \n",
    "        # For simplicity, we'll just use a predefined best configuration\n",
    "        # In a real implementation, you'd perform grid search or random search\n",
    "        print(\"Note: Using predefined hyperparameters for demonstration.\")\n",
    "        print(\"In a real implementation, this would perform actual hyperparameter optimization.\")\n",
    "        \n",
    "        if model_name == \"pointnet++\":\n",
    "            best_params = {\"lr\": 0.001, \"weight_decay\": 0.001, \"batch_size\": 32}\n",
    "        elif model_name == \"dgcnn\":\n",
    "            best_params = {\"lr\": 0.001, \"weight_decay\": 0.001, \"batch_size\": 32, \"k\": 20}\n",
    "        elif model_name == \"pointmlp\":\n",
    "            best_params = {\"lr\": 0.001, \"weight_decay\": 0.001, \"batch_size\": 32, \"embed_dim\": 64}\n",
    "        else:  # Custom attention model\n",
    "            best_params = {\"lr\": 0.001, \"weight_decay\": 0.001, \"batch_size\": 32, \"embed_dim\": 128, \"heads\": 4}\n",
    "        \n",
    "        # Remove training-specific parameters to keep only model initialization parameters\n",
    "        model_params = {k: v for k, v in best_params.items() if k not in [\"lr\", \"weight_decay\", \"batch_size\"]}\n",
    "        \n",
    "        return model_params\n",
    "\n",
    "\n",
    "class BenchmarkProtocol:\n",
    "    \"\"\"Class for benchmarking procedures\"\"\"\n",
    "    \n",
    "    def __init__(self, device=None):\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def benchmark_models(self, models, test_loader):\n",
    "        \"\"\"\n",
    "        Benchmark multiple models on classification performance\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        models: dict, {name: model} dictionary\n",
    "        test_loader: DataLoader, test data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results: dict, benchmark results\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            model.eval()\n",
    "            model.to(self.device)\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            inference_times = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for points, labels in tqdm(test_loader, desc=f\"Benchmarking {name}\"):\n",
    "                    points, labels = points.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Measure inference time\n",
    "                    start_time = time.time()\n",
    "                    outputs = model(points)\n",
    "                    inference_time = time.time() - start_time\n",
    "                    inference_times.append(inference_time)\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            accuracy = correct / total\n",
    "            avg_inference_time = sum(inference_times) / len(inference_times)\n",
    "            \n",
    "            results[name] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"avg_inference_time_ms\": avg_inference_time * 1000\n",
    "            }\n",
    "            \n",
    "            print(f\"{name}: Accuracy = {accuracy:.4f}, Avg. Inference Time = {avg_inference_time*1000:.2f} ms\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# Fix the ExperimentalProtocol class that was duplicated and incomplete\n",
    "def _evaluate_adversarial_robustness(model, dataloader, attacker, attack_type, strength):\n",
    "    \"\"\"Helper method to evaluate adversarial robustness\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for points, labels in dataloader:\n",
    "        points, labels = points.to(attacker.device), labels.to(attacker.device)\n",
    "        \n",
    "        # Generate adversarial examples\n",
    "        if attack_type == 'fgsm':\n",
    "            adv_points = attacker.fgsm_attack(points, labels, epsilon=strength)\n",
    "        elif attack_type == 'pgd':\n",
    "            adv_points = attacker.pgd_attack(points, labels, epsilon=strength, alpha=strength/4)\n",
    "            \n",
    "        # Evaluate\n",
    "        with torch.no_grad():\n",
    "            outputs = model(adv_points)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
